{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "sys.path.append('/home/peter/code/projects/')\n",
    "sys.path.append('/home/ubuntu/')\n",
    "from aidevutil import *\n",
    "from massimport import *\n",
    "from sklearn import datasets\n",
    "\n",
    "import project_common, genetic, paramspace\n",
    "from project_common import *\n",
    "from paramspace import *\n",
    "from itertools import product\n",
    "from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, IterativeImputer, BiScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.benchmarks import branin as branin\n",
    "from skopt.benchmarks import hart6 as hart6_\n",
    "from functools import partial\n",
    "from skopt.plots import plot_evaluations, plot_convergence\n",
    "from skopt.plots import plot_objective\n",
    "from skopt import gp_minimize, forest_minimize, dummy_minimize\n",
    "from skopt import callbacks\n",
    "#from skopt.callbacks import CheckpointSaver\n",
    "from skopt import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if socket.gethostname() in ['laptop','desktop']:\n",
    "#    %load_ext birdseye\n",
    "#    %config BirdsEyeMagics.port = 7777\n",
    "#    %config BirdsEyeMagics.bind_host = '192.168.1.149'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "parallel = 0\n",
    "num_trials = 1\n",
    "use_CV = 1\n",
    "CV_splits = 5\n",
    "test_size = 1/5\n",
    "datasplit_mode = 'random'\n",
    "use_preps = 0\n",
    "use_hpo = 0\n",
    "exhaustive_search_on = 1\n",
    "genetic_search_on = 0\n",
    "min_ensemble_size=1\n",
    "max_ensemble_size=3\n",
    "\n",
    "stack_original_level1 = False\n",
    "optimized_voting = 1\n",
    "voting_opt_trials = 10000\n",
    "\n",
    "pdict = dict(num_trials=1, use_CV=use_CV, CV_splits=CV_splits)\n",
    "\n",
    "min_population_size = 128\n",
    "num_generations = 5\n",
    "max_evaluations = 5000\n",
    "generational_mode = 0\n",
    "plot_nns = 0\n",
    "\n",
    "nrows = 10000000\n",
    "hpo_nrows = 10000000\n",
    "use_hpo_skopt = 0\n",
    "\n",
    "prediction_mode = 'binary_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_version = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic4.MinNumClassifiers = min_ensemble_size\n",
    "genetic4.MaxNumClassifiers = max_ensemble_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdict['prediction_mode'] = prediction_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_titanic = 0\n",
    "using_gacrp = 0\n",
    "using_elo = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mode = 'kaggle'\n",
    "# using_titanic = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(dx, dy), (x_test, y_test) = get_mnist(nrows=500)\n",
    "dx.shape = dx.shape[0], -1\n",
    "dy = dy.astype(np.int)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 31\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/31.csv')\n",
    "x_cols = [c for c in df.columns if c != 'target']\n",
    "x = df[x_cols].as_matrix()\n",
    "y = df['target'].as_matrix()\n",
    "\n",
    "#if data_mode != 'kaggle':\n",
    "#    dx, x_val_real, dy, y_val_real = train_test_split(dx, dy, test_size=0.2, random_state = rnd.randint(0, 100000)) # we don't need the new datasplit() method here\n",
    "dx = x\n",
    "dy = y\n",
    "x_val_real = x\n",
    "dx.shape, dy.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Load Titanic\n",
    "if titanic_version == 1:\n",
    "    dx, dy, x_val_real, p_id = get_titanic()\n",
    "    idx = arange(dx.shape[0])\n",
    "    rnd.shuffle(idx)\n",
    "    dx = dx[idx, ...]\n",
    "    dy = dy[idx, ...]\n",
    "elif titanic_version == 2:\n",
    "    dx, dy, x_val_real = get_titanic2()\n",
    "\n",
    "using_titanic = 1\n",
    "dx.shape, dy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataname = 'eurusd_1h'\n",
    "input_source = np.load(\"data/data_%s.npy\" % dataname)\n",
    "to_predict = np.load(\"data/data_%s_targets.npy\" % dataname)\n",
    "to_predict = to_predict[3,:].reshape(-1)\n",
    "input_source = input_source.T\n",
    "is_orig = np.copy(input_source)\n",
    "cp = int(0.8*len(input_source))\n",
    "test_input_source = input_source[cp:, :]\n",
    "test_to_predict = to_predict[cp:]\n",
    "input_source = input_source[0:cp, :]\n",
    "to_predict = to_predict[0:cp]\n",
    "test_input_source = test_input_source.T\n",
    "input_source = input_source.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "winlen = 1\n",
    "sliding_window_jump = 1\n",
    "predict_time_ahead = 1\n",
    "binary = 1\n",
    "\n",
    "def prepare_data(input_source, to_predict, binary=1, cpp=0.75):\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    ups = []\n",
    "    downs = []\n",
    "    mids = []\n",
    "\n",
    "    for i in range(0, input_source.shape[1]-(winlen+100), sliding_window_jump):\n",
    "        # form the input\n",
    "        txs = input_source[:, i:i+winlen]#.astype(np.float64)\n",
    "        #xs = scale(xs, axis=1)\n",
    "        xs = txs.ravel()\n",
    "\n",
    "        # for the output\n",
    "        now = to_predict[i+winlen-1]# close\n",
    "        future = to_predict[i+winlen+(predict_time_ahead-1)] # next close\n",
    "\n",
    "        ys = future-now\n",
    "        magn = abs(ys)\n",
    "\n",
    "        if not binary:\n",
    "            if magn < sep:\n",
    "                mids.append( (xs, (np.array([1]))) )\n",
    "            else:\n",
    "                if ys < 0:\n",
    "                    downs.append( (xs, (np.array([2]))) )\n",
    "                else:\n",
    "                    ups.append( (xs, (np.array([0]))) )\n",
    "        else:\n",
    "            if ys <= 0:\n",
    "                downs.append( (xs, (np.array([1]))) )\n",
    "            else:\n",
    "                ups.append( (xs, (np.array([0]))) )\n",
    "\n",
    "        #if (i%1000)==0:\n",
    "        #    clear_output(wait=True)\n",
    "        #    print('({}/{})'.format(i, input_source.shape[1]-winlen))\n",
    "\n",
    "    #print('Ups: {0} Mids: {1} Downs: {2}'.format(len(ups), len(mids), len(downs)))\n",
    "    #print('Separator: %3.5f' % sep)\n",
    "    #print()\n",
    "\n",
    "    if not binary:\n",
    "        samplesize = min(len(ups), len(downs), len(mids))\n",
    "        s1 = rnd.sample(ups, samplesize)\n",
    "        s2 = rnd.sample(downs, samplesize)\n",
    "        s3 = rnd.sample(mids, samplesize)\n",
    "        a = s1 + s2 + s3\n",
    "    else:\n",
    "        samplesize = min(len(ups), len(downs))\n",
    "        s1 = rnd.sample(ups, samplesize)\n",
    "        s2 = rnd.sample(downs, samplesize)\n",
    "        a = s1 + s2 \n",
    "    rnd.shuffle(a)\n",
    "    x = [x[0] for x in a]\n",
    "    y = [x[1] for x in a]\n",
    "\n",
    "    x = np.vstack(x)\n",
    "    y = np.vstack(y)\n",
    "    \n",
    "    x.shape = (x.shape[0], -1)\n",
    "    cutpoint = int(cpp * x.shape[0])\n",
    "    x_train = x[0:cutpoint]\n",
    "    x_test = x[cutpoint:]\n",
    "    y_train = y[0:cutpoint]\n",
    "    y_test = y[cutpoint:]\n",
    "    \n",
    "    return x_train, x_test, y_train.reshape(-1), y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_data(input_source, to_predict)\n",
    "\n",
    "dx = vstack([x_train, x_test])\n",
    "dy = hstack([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_real = dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = dx[0:nrows]\n",
    "dy = dy[0:nrows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dx[where(isnan(dx))] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8,
     13
    ]
   },
   "outputs": [],
   "source": [
    "if parallel:\n",
    "    ic = \"\"\"\n",
    "from aidevutil import *\n",
    "from massimport import *\n",
    "from project_common import *\n",
    "from paramspace import *\n",
    "    \"\"\"\n",
    "\n",
    "    if socket.gethostname() not in ['laptop', 'desktop']:\n",
    "        idirs = ['/home/ubuntu', \n",
    "                 ]\n",
    "        chd = ['/home/ubuntu/new/automl', \n",
    "               ]\n",
    "    else:\n",
    "        idirs = [ \n",
    "                 '/home/peter/code/projects']\n",
    "        chd = [ \n",
    "               '/home/peter/code/work/automl']\n",
    "\n",
    "\n",
    "    objs = {}\n",
    "    objs['dx'] = dx\n",
    "    objs['dy'] = dy\n",
    "    objs['pdict'] = pdict\n",
    "    objs['decode_classifier'] = decode_classifier\n",
    "    objs['decode_classifier_mc'] = decode_classifier_mc\n",
    "    objs['decode_classifier2'] = decode_classifier2\n",
    "    objs['decode_regressor'] = decode_regressor\n",
    "    objs['decode_preprocessor'] = decode_preprocessor\n",
    "    objs['mappings'] = mappings\n",
    "    objs['mappings_2nd_level'] = mappings_2nd_level\n",
    "    objs['sk_classes'] = sk_classes\n",
    "    objs['rg_classes'] = rg_classes\n",
    "    objs['pc_classes'] = pc_classes\n",
    "    objs['mc_classes'] = mc_classes\n",
    "    objs['prediction_mode'] = prediction_mode\n",
    "    objs = {**objs, **sk1_classes, **sk_classes, **rg_classes, **sndlev_classes, **pc_classes}\n",
    "\n",
    "    rc, dview, lbview = init_ipyparallel(cluster_name='default', use_dill=False, imports_code = ic, \n",
    "                                         idirs = idirs, prep_code = None, chdirs = chd, objects = objs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test all models first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [(k,{},dx,dy,pdict) \n",
    "        for k in ar_mapping[prediction_mode].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "if not parallel:\n",
    "    rs = []\n",
    "    for x in args:\n",
    "        try:\n",
    "            l = x[0], general_compute(x)\n",
    "            print(l)\n",
    "            rs.append(l)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "else:\n",
    "    # evaluate all in parallel \n",
    "    rs = []\n",
    "    pb = pbar.ProgressBar(max_value=len(args))\n",
    "    for i, (r, x) in enumerate(zip(lbview.imap(general_compute, args, ordered=True), args)):\n",
    "        pb.update(i)\n",
    "        #print(pr, ms, sl, '%3.4f' % r)\n",
    "        ms = x[0]\n",
    "        rs.append((ms, r))\n",
    "    pb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sort_mapping[prediction_mode] == 'min':\n",
    "    srs = sorted(rs, key=lambda x: x[1], reverse=0)\n",
    "else:\n",
    "    srs = sorted(rs, key=lambda x: x[1], reverse=1)\n",
    "srs = [x for x in srs if x[1] != -0.01 and not isnan(x[1])]\n",
    "srs, len(srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=3\n",
    "models = [x[0] for x in srs[0:N]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preps = list(pc_classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_preps: preps = ['Raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdx = dx[0:hpo_nrows]\n",
    "hdy = dy[0:hpo_nrows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = \"/tmp/checkpoint_%s.pkl\" % uuname()\n",
    "#checkpoint_saver = CheckpointSaver(fname, compress=9)\n",
    "\n",
    "def optimize_classifier(classifier, verbose=True):\n",
    "    order = sorted(list(param_spaces[classifier].keys()))\n",
    "\n",
    "    def testclf(args):\n",
    "        ps = {}\n",
    "        for a,o in zip(args,order):\n",
    "            sp = param_spaces[classifier][o]['space']\n",
    "            if isinstance(sp[0], int) and isinstance(sp[1], int):\n",
    "                ps[o] = a\n",
    "            elif isinstance(sp[0], float) and isinstance(sp[1], float):\n",
    "                ps[o] = a\n",
    "            else:\n",
    "                ps[o] = param_spaces[classifier][o]['space'][a]\n",
    "        return general_compute((classifier, ps, hdx, hdy, pdict))\n",
    "    \n",
    "    bl = []\n",
    "    for o in order:\n",
    "        sp = param_spaces[classifier][o]['space']\n",
    "        if isinstance(sp[0], int) and isinstance(sp[1], int):\n",
    "            bl.append((sp[0], sp[1]))\n",
    "        elif isinstance(sp[0], float) and isinstance(sp[1], float):\n",
    "            bl.append((sp[0], sp[1]))\n",
    "        else:\n",
    "            bl.append( (0, len(sp)-1) )\n",
    "\n",
    "    res=None\n",
    "    try:\n",
    "        res = gp_minimize(testclf, bl, \n",
    "                          n_calls=50,\n",
    "                          n_random_starts=10, \n",
    "                          #callback=[checkpoint_saver],\n",
    "                          #noise=variance_data[classifier],\n",
    "                          verbose=verbose)\n",
    "    except KeyboardInterrupt:\n",
    "        pass#res = load(fname)\n",
    "    \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        \n",
    "    a = list(zip(order,res.x))\n",
    "    na = []\n",
    "    for o, am in a:\n",
    "        sp = param_spaces[classifier][o]['space']\n",
    "        if isinstance(sp[0], int) and isinstance(sp[1], int):\n",
    "            na.append( [o, am] )\n",
    "        elif isinstance(sp[0], float) and isinstance(sp[1], float):\n",
    "            na.append( [o, am] )\n",
    "        else:\n",
    "            na.append( [o, param_spaces[classifier][o]['space'][am]] )\n",
    "        \n",
    "    return dict(na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-optimize the classifiers\n",
    "if use_hpo_skopt:\n",
    "    nsrs = []\n",
    "    optimized = {}\n",
    "    for c,sc in srs:\n",
    "        if (c in param_spaces) and param_spaces[c]:\n",
    "            d= optimize_classifier(c, verbose=1)\n",
    "            nsc = [general_compute((c, d, dx, dy, pdict)) for _ in tqdm(range(variance_d))]\n",
    "            nsrs.append((c,nsc))\n",
    "            optimized[c] = d\n",
    "            print(c,mean(nsc))\n",
    "        else:\n",
    "            nsrs.append((c,sc))\n",
    "            optimized[c] = {}\n",
    "\n",
    "    nsrs = sorted(nsrs, key=lambda x: mean(x[1]))\n",
    "\n",
    "    # encode into model names\n",
    "    models = [x[0]+' '+str(optimized[x[0]]) for x in nsrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def all_combs(models, n=2):\n",
    "    ax = [models[:]]*n\n",
    "    mx= [sorted(x) for x in list(product(*ax))]\n",
    "    mx= [tuple(x) for x in mx if len(np.unique(x)) == len(x) ]\n",
    "    mx= list(set(mx))\n",
    "    return mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# HPO for all classifiers\n",
    "if use_hpo:\n",
    "    newmodels = []\n",
    "    for k in models:\n",
    "        if k in param_spaces and param_spaces[k]:\n",
    "            ck= {k:v['space'] for k,v in param_spaces[k].items()}\n",
    "            mk= list(product(*[v for k,v in sorted(ck.items())]))\n",
    "\n",
    "            ks = [k for k,v in sorted(ck.items())]\n",
    "            for m in mk:\n",
    "                enc = str({k:v for k,v in zip(ks,m)})\n",
    "                newmodels.append(k+' '+enc)\n",
    "                #print(k+' '+enc)\n",
    "        else:\n",
    "            newmodels.append(k)\n",
    "            #print(k)\n",
    "            \n",
    "    models = newmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# HPO for all preprocessors\n",
    "if use_hpo and use_preps:\n",
    "    newpreps = []\n",
    "    for k in preps:\n",
    "        if k in param_spaces and param_spaces[k]:\n",
    "            ck= {k:v['space'] for k,v in param_spaces[k].items()}\n",
    "            mk= list(product(*[v for k,v in sorted(ck.items())]))\n",
    "\n",
    "            ks = [k for k,v in sorted(ck.items())]\n",
    "            for m in mk:\n",
    "                enc = str({k:v for k,v in zip(ks,m)})\n",
    "                newpreps.append(k+' '+enc)\n",
    "                #print(k+' '+enc)\n",
    "        else:\n",
    "            newpreps.append(k)\n",
    "            #print(k)\n",
    "\n",
    "    preps = newpreps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lenght of models after HPO\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the models\n",
    "rnd.shuffle(models)\n",
    "models[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precomputing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocessed data \n",
    "dpx = {}\n",
    "dpxv = {}\n",
    "dpy = {}\n",
    "dpyv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdpx = {}\n",
    "mdpxv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     3
    ],
    "pixiedust": {
     "displayParams": {}
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%%eye\n",
    "#%%pixie_debugger\n",
    "\n",
    "if not parallel:\n",
    "    \n",
    "    pb = pbar.ProgressBar(max_value=len(preps)*num_trials + len(models)*len(preps)*num_trials )\n",
    "    pl=0\n",
    "    for trial in range(num_trials):\n",
    "        data_x, x_val, data_y, y_val = datasplit(dx, dy, trial, num_trials=num_trials, test_size=test_size, mode=datasplit_mode)\n",
    "        \n",
    "        dpxt = {}\n",
    "        dpxvt = {}\n",
    "        \n",
    "        # Preprocessing\n",
    "        for i,n in enumerate(preps):\n",
    "            c = decode_preprocessor(n,{})\n",
    "            try:\n",
    "                c.fit(data_x, data_y)\n",
    "            except:\n",
    "                try:\n",
    "                    c.fit(data_x)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            try:\n",
    "                dpxt[n] = c.transform( data_x )\n",
    "                dpxvt[n] = c.transform( x_val )\n",
    "            except Exception as ex:\n",
    "                print(n, ex)\n",
    "            \n",
    "            pb.update(pl)\n",
    "            pl += 1\n",
    "\n",
    "        dpx[trial] = dpxt\n",
    "        dpxv[trial] = dpxvt \n",
    "        dpy[trial] = data_y\n",
    "        dpyv[trial] = y_val\n",
    "        \n",
    "    for trial in range(num_trials):\n",
    "        mdpx[trial] = {}\n",
    "        mdpxv[trial] = {}\n",
    "        \n",
    "        for pn in preps:\n",
    "            mdpx[trial][pn] = {}\n",
    "            mdpxv[trial][pn] = {}\n",
    "            \n",
    "            for n in models:\n",
    "                # fit classifier on data\n",
    "                c = mappings[prediction_mode](n, prediction_mode)\n",
    "\n",
    "                try:\n",
    "                    c.fit(dpx[trial][pn], dpy[trial])\n",
    "\n",
    "                    mdpx[trial][pn][n] = predictor(c, prediction_mode)( dpx[trial][pn] )\n",
    "                    mdpxv[trial][pn][n] = predictor(c, prediction_mode)( dpxv[trial][pn] )\n",
    "                    \n",
    "                except Exception as ex:\n",
    "                    print(n, ex)\n",
    "                \n",
    "                pb.update(pl)\n",
    "                pl += 1\n",
    "                \n",
    "    pb.finish(end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdpx[0]['Raw']['SVC'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     12,
     29,
     30,
     40
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Parallel version of the above\n",
    "def evala(args):\n",
    "    trial, n, pn = args\n",
    "    try:\n",
    "        c = mappings[prediction_mode](n,{})\n",
    "        c.fit(dpx[trial][pn], dpy[trial])\n",
    "        p= predictor(c, prediction_mode)( dpx[trial][pn] )\n",
    "        pv = predictor(c, prediction_mode)( dpxv[trial][pn] )\n",
    "        return n, p, pv\n",
    "    except:\n",
    "        return n, None, None\n",
    "\n",
    "def evalp(n):\n",
    "    try:\n",
    "        c = decode_preprocessor(n,{})\n",
    "        c.fit(data_x, data_y)\n",
    "    except:\n",
    "        try:\n",
    "            c.fit(data_x)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        p= c.transform( data_x ).astype(np.float).reshape(data_y.shape[0], -1)\n",
    "        pv = c.transform( x_val ).astype(np.float).reshape(y_val.shape[0], -1)\n",
    "        return n, p, pv\n",
    "    except:\n",
    "        return n, None, None\n",
    "\n",
    "if parallel:\n",
    "    for trial in range(num_trials):\n",
    "        data_x, x_val, data_y, y_val = datasplit(dx, dy, trial, num_trials=num_trials, test_size=test_size, mode=datasplit_mode)\n",
    "       # if prediction_mode != 'regression':\n",
    "        #    data_y.shape = -1, 1\n",
    "         #   y_val.shape = -1, 1\n",
    "        \n",
    "        dpxt = {}\n",
    "        dpxvt = {}\n",
    "        \n",
    "        # update objects on cluster\n",
    "        if use_preps:\n",
    "            objs={}\n",
    "            objs['data_x'] = data_x\n",
    "            objs['data_y'] = data_y\n",
    "            objs['x_val'] = x_val\n",
    "            objs['y_val'] = y_val\n",
    "\n",
    "            print('Sending objects to engines.. ', end='')\n",
    "            kv = list(objs.items())\n",
    "            for k, v in kv:\n",
    "                if k != kv[-1][0]:\n",
    "                    print(k, end=', ')\n",
    "                else:\n",
    "                    print(k, end='..')\n",
    "                dview[k] = v\n",
    "            dview.wait()\n",
    "            print(' Done.')\n",
    "\n",
    "            pb = pbar.ProgressBar(max_value=len(preps))\n",
    "            for i, (n, p, pv) in enumerate(lbview.imap(evalp, preps)):\n",
    "                dpxt[n] = p\n",
    "                dpxvt[n] = pv\n",
    "                pb.update(i)\n",
    "            pb.finish(end='\\r')\n",
    "        else:\n",
    "            n='Raw'\n",
    "            dpxt[n] = data_x\n",
    "            dpxvt[n] = x_val\n",
    "        \n",
    "        dpx[trial] = dpxt\n",
    "        dpxv[trial] = dpxvt \n",
    "        dpy[trial] = data_y\n",
    "        dpyv[trial] = y_val\n",
    "        \n",
    "    # update objects on cluster\n",
    "    objs={}\n",
    "    objs['dpx'] = dpx\n",
    "    objs['dpxv'] = dpxv\n",
    "    objs['dpy'] = dpy\n",
    "    objs['dpyv'] = dpyv\n",
    "    print('Sending objects to engines.. ', end='')\n",
    "    kv = list(objs.items())\n",
    "    for k, v in kv:\n",
    "        if k != kv[-1][0]:\n",
    "            print(k, end=', ')\n",
    "        else:\n",
    "            print(k, end='..')\n",
    "        dview[k] = v\n",
    "    dview.wait()\n",
    "    print(' Done.')\n",
    "    \n",
    "    pb = pbar.ProgressBar(max_value=len(models)*len(preps)*num_trials)\n",
    "    pl = 0\n",
    "    for trial in range(num_trials):\n",
    "        mdpx[trial] = {}\n",
    "        mdpxv[trial] = {}\n",
    "        for pn in preps:\n",
    "            mdpx[trial][pn] = {}\n",
    "            mdpxv[trial][pn] = {}\n",
    "            args = [(trial, n, pn) for n in models]\n",
    "            for i, (n, p, pv) in enumerate(lbview.imap(evala, args)):\n",
    "                mdpx[trial][pn][n] = p \n",
    "                mdpxv[trial][pn][n] = pv \n",
    "                pb.update(pl)\n",
    "                pl += 1\n",
    "    pb.finish(end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking and voting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores2 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     13
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# test non-stack\n",
    "def test_regular(prep, stack, weights=None):\n",
    "    accs=[]\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        # get predictions for x-val\n",
    "        am = [mdpxv[trial][prep][n] for n in stack]\n",
    "        a = voting_mixer(am, weights, prediction_mode)\n",
    "        a = afterprocessing_mapping[prediction_mode](a)\n",
    "        accs.append( metrics_mapping[prediction_mode](dpyv[trial], a) )\n",
    "        \n",
    "    return float(mean(accs))\n",
    "\n",
    "def test_regular_par(args):\n",
    "    prep, stack, = args\n",
    "    try:\n",
    "        weights=None\n",
    "        if optimized_voting:\n",
    "            ms=stack\n",
    "            x0 = array([1/len(ms)]*len(ms))\n",
    "            rzs = []\n",
    "            for it in range(voting_opt_trials):\n",
    "                magn = 0.8 if prediction_mode != 'regression' else 0.8\n",
    "                r = x0 + np.random.uniform(low=-1 / len(ms) * magn, high=1 / len(ms) * magn, size=(len(ms),))\n",
    "                rs = test_regular(prep, ms, weights=r)\n",
    "                rzs.append((rs,r))\n",
    "            ar = array([x[0] for x in rzs])\n",
    "            if prediction_mode == 'regression':\n",
    "                idx = where(ar==min(ar))[0][0]\n",
    "            else:\n",
    "                idx = where(ar==max(ar))[0][0]\n",
    "            r, weights = ar[idx], rzs[idx][1]\n",
    "        else:\n",
    "            ms=stack\n",
    "            r= test_regular(prep, ms)\n",
    "        return r, prep, ms, weights\n",
    "    except:\n",
    "        return -1 if prediction_mode != 'regression' else 99999999, prep, stack, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pixiedust": {
     "displayParams": {}
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger \n",
    "\n",
    "def test_stack(prep, stack, slc):\n",
    "    kp = []\n",
    "    pts = None\n",
    "    nnn= 'dummy'\n",
    "    accs=[]\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        # get predictions for x\n",
    "        if prediction_mode!='multiclass_classification':\n",
    "            am = [mdpx[trial][prep][n].reshape(-1,1) for n in stack]\n",
    "            if stack_original_level1:\n",
    "                am.append( dpx[trial]['Raw'].reshape(-1,1) )\n",
    "        else:\n",
    "            am = [mdpx[trial][prep][n] for n in stack]\n",
    "            if stack_original_level1:\n",
    "                am.append( dpx[trial]['Raw'] )\n",
    "        am = hstack(am)\n",
    "\n",
    "        clf = mappings_2nd_level[prediction_mode](slc,prediction_mode)\n",
    "        clf.fit(am, dpy[trial])\n",
    "        # now predict on the validation set\n",
    "        # get the individual classifier predictions, stack them, get the second level prediction\n",
    "        if prediction_mode!='multiclass_classification':\n",
    "            ps = [mdpxv[trial][prep][n].reshape(-1,1) for n in stack]\n",
    "            if stack_original_level1:\n",
    "                ps.append( dpxv[trial]['Raw'].reshape(-1,1) )\n",
    "        else:\n",
    "            ps = [mdpxv[trial][prep][n] for n in stack]\n",
    "            if stack_original_level1:\n",
    "                ps.append( dpxv[trial]['Raw'] )\n",
    "        ps = hstack(ps)\n",
    "        a = clf.predict(ps)\n",
    "        a = a.astype(np.float)\n",
    "        \n",
    "        if pts is not None:\n",
    "            ms = min(a.shape[0], pts.shape[0])\n",
    "        else:\n",
    "            ms = a.shape[0]\n",
    "        if pts is not None: pts[0:ms,...] += a[0:ms, ...]\n",
    "        else: pts = a\n",
    "        \n",
    "        a = afterprocessing_mapping[prediction_mode](a)\n",
    "        accs.append( metrics_mapping[prediction_mode](dpyv[trial], a) )\n",
    "        \n",
    "    pts /= num_trials\n",
    "    \n",
    "    return float(mean(accs))\n",
    "\n",
    "def test_stack_par(args):\n",
    "    p, s, d = args\n",
    "    try:\n",
    "        return test_stack(p,s,d), p, s, d\n",
    "    except Exception as ex:\n",
    "        return -1 if prediction_mode != 'regression' else 99999999, p, s, d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exhaustive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pixiedust": {
     "displayParams": {}
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "# Test all combinations for stack lengths from 1 to 8 and all preprocessors\n",
    "if exhaustive_search_on:\n",
    "    comblens = 0\n",
    "    mxs = []\n",
    "    for n in range(min_ensemble_size, max_ensemble_size+1):\n",
    "        mx = all_combs(models, n=n)\n",
    "        comblens += len(mx)\n",
    "        mxs.append(mx)\n",
    "        \n",
    "    if not parallel:\n",
    "        thekeys = ar_mapping[prediction_mode].keys()\n",
    "        allr = []\n",
    "        pb = pbar.ProgressBar(max_value=len(list(thekeys))*len(preps)*comblens)\n",
    "        pl=0\n",
    "        for sl in thekeys:\n",
    "            for pr in preps:\n",
    "                for mx in mxs:\n",
    "                    for ms in mx:\n",
    "                        if 1:\n",
    "                            r= test_stack(pr, ms, sl)\n",
    "                        #except Exception as ex:\n",
    "                        #    print(ex)\n",
    "                        #    r = -1 if prediction_mode != 'regression' else 99999999\n",
    "                        #print(pr, ms, sl, '%3.4f' % r)\n",
    "                        allr.append((r, pr, ms, sl))\n",
    "                        scores[ms] = r\n",
    "                        pb.update(pl)\n",
    "                        pl += 1\n",
    "        pb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Parallel version of the above\n",
    "if exhaustive_search_on:\n",
    "    if parallel:\n",
    "        # update objects on cluster\n",
    "        objs={}\n",
    "        objs['test_stack'] = test_stack\n",
    "        objs['stack_original_level1'] = stack_original_level1\n",
    "        objs['test_stack_par'] = test_stack_par\n",
    "        objs['test_regular'] = test_regular\n",
    "        objs['test_regular_par'] = test_regular_par\n",
    "        objs['num_trials'] = num_trials\n",
    "        objs['optimized_voting'] = optimized_voting\n",
    "        objs['where'] = where\n",
    "        objs['voting_opt_trials'] = voting_opt_trials\n",
    "        objs['prediction_mode'] = prediction_mode\n",
    "        objs['mdpx'] = mdpx\n",
    "        objs['mdpxv'] = mdpxv\n",
    "        objs['dpy'] = dpy\n",
    "        objs['dpyv'] = dpyv\n",
    "        objs['mean'] = mean\n",
    "        objs['hstack'] = hstack\n",
    "        objs['vstack'] = vstack\n",
    "        objs['decode_classifier2'] = decode_classifier2\n",
    "        #objs['regression_metric'] = regression_metric\n",
    "\n",
    "        print('Sending objects to engines.. ', end='')\n",
    "        kv = list(objs.items())\n",
    "        for k, v in kv:\n",
    "            if k != kv[-1][0]:\n",
    "                print(k, end=', ')\n",
    "            else:\n",
    "                print(k, end='..')\n",
    "            dview[k] = v\n",
    "        dview.wait()\n",
    "        print(' Done.')\n",
    "\n",
    "        args = []\n",
    "        allr = []\n",
    "        thekeys = sndlev_classes.keys() if prediction_mode != 'regression' else rg_classes.keys()\n",
    "        for sl in thekeys:\n",
    "            for pr in preps:\n",
    "                for n in range(min_ensemble_size, max_ensemble_size+1):\n",
    "                    mx = all_combs(models, n=n)\n",
    "                    for ms in mx:\n",
    "                        args.append((pr, ms, sl))\n",
    "\n",
    "        # evaluate all in parallel \n",
    "        pb = pbar.ProgressBar(max_value=len(args))\n",
    "        for i, (r, pr, ms, sl) in enumerate(lbview.imap(test_stack_par, args)):\n",
    "            pb.update(i)\n",
    "            #print(pr, ms, sl, '%3.4f' % r)\n",
    "            scores[ms] = r\n",
    "            allr.append((r, pr, ms, sl))\n",
    "        pb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "if exhaustive_search_on:\n",
    "    if prediction_mode == 'regression':\n",
    "        for x in sorted(allr, key=lambda x: x[0], reverse=False)[0:5]:\n",
    "            print(x)\n",
    "    else:\n",
    "        for x in sorted(allr, key=lambda x: x[0], reverse=True)[0:5]:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%%eye\n",
    "\n",
    "if exhaustive_search_on:\n",
    "    if not parallel:\n",
    "        allr2 = []\n",
    "        for pr in preps:\n",
    "            for n in range(min_ensemble_size, max_ensemble_size+1):\n",
    "                mx = all_combs(models, n=n)\n",
    "                for ms in mx:\n",
    "                    weights=None\n",
    "                    if optimized_voting:\n",
    "                        x0 = array([1/len(ms)]*len(ms))\n",
    "                        rzs = []\n",
    "                        for it in range(voting_opt_trials):\n",
    "                            r = x0 + np.random.uniform(low=-1 / len(ms) * 0.8, high=1 / len(ms) * 0.8, size=(len(ms),))\n",
    "                            rs = test_regular(pr, ms, weights=r)\n",
    "                            rzs.append((rs,r))\n",
    "                        ar = array([x[0] for x in rzs])\n",
    "                        if prediction_mode == 'regression':\n",
    "                            idx = where(ar==min(ar))[0][0]\n",
    "                        else:\n",
    "                            idx = where(ar==max(ar))[0][0]\n",
    "                        r, weights = ar[idx], rzs[idx][1]\n",
    "                    else:\n",
    "                        r= test_regular(pr, ms)\n",
    "                    print(pr, ms,'%3.4f' % r)\n",
    "                    scores2[ms] = r\n",
    "                    allr2.append((r, pr, ms, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "#%%eye\n",
    "\n",
    "if exhaustive_search_on:\n",
    "    if parallel:\n",
    "        # update objects on cluster\n",
    "        objs={}\n",
    "        objs['test_stack'] = test_stack\n",
    "        objs['test_regular'] = test_regular\n",
    "        objs['test_regular_par'] = test_regular_par\n",
    "        objs['num_trials'] = num_trials\n",
    "        objs['mdpx'] = mdpx\n",
    "        objs['mdpxv'] = mdpxv\n",
    "        objs['dpy'] = dpy\n",
    "        objs['dpyv'] = dpyv\n",
    "        objs['mean'] = mean\n",
    "\n",
    "        print('Sending objects to engines.. ', end='')\n",
    "        kv = list(objs.items())\n",
    "        for k, v in kv:\n",
    "            if k != kv[-1][0]:\n",
    "                print(k, end=', ')\n",
    "            else:\n",
    "                print(k, end='..')\n",
    "            dview[k] = v\n",
    "        dview.wait()\n",
    "        print(' Done.')\n",
    "\n",
    "        args = []\n",
    "        allr2 = []\n",
    "        for pr in preps:\n",
    "            for n in range(min_ensemble_size, max_ensemble_size+1):\n",
    "                mx = all_combs(models, n=n)\n",
    "                for ms in mx:\n",
    "                    args.append((pr,ms))\n",
    "\n",
    "        # evaluate all in parallel \n",
    "        pb = pbar.ProgressBar(max_value=len(args))\n",
    "        for i, (r, pr, ms, weights) in enumerate(lbview.imap(test_regular_par, args)):\n",
    "            pb.update(i)\n",
    "            #print(pr, ms,  '%3.4f' % r)\n",
    "            scores2[ms] = r\n",
    "            allr2.append((r, pr, ms, weights))\n",
    "        pb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exhaustive_search_on:\n",
    "    if prediction_mode == 'regression':\n",
    "        for x in sorted(allr2, key=lambda x: x[0], reverse=False)[0:5]:\n",
    "            print(x)\n",
    "    else:\n",
    "        for x in sorted(allr2, key=lambda x: x[0], reverse=True)[0:5]:\n",
    "            print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     17
    ]
   },
   "outputs": [],
   "source": [
    "genetic4.models = models\n",
    "genetic4.prep_models = preps\n",
    "\n",
    "def evaluate_genome(asd):\n",
    "    idx, traits, genome = asd\n",
    "    wc, pp, slc = traits\n",
    "    try:\n",
    "        acc = test_stack(pp, wc, slc) # it does the many trials in test_stack\n",
    "    except:\n",
    "        acc = -1 \n",
    "    #print(wc, acc)\n",
    "    return idx, acc\n",
    "\n",
    "def evaluate_genome_regular(asd):\n",
    "    idx, traits, genome = asd\n",
    "    wc, pp, slc = traits\n",
    "    try:\n",
    "        acc = test_regular(pp, wc) # it does the many trials in test_stack\n",
    "    except:\n",
    "        acc = -1\n",
    "    #print(wc, acc)\n",
    "    return idx, acc\n",
    "\n",
    "def thetraits(x):\n",
    "    return (x.GetGenomeTraits()['x'].cltypes, x.GetGenomeTraits()['x'].pp, x.GetGenomeTraits()['x'].slc )\n",
    "\n",
    "def eval_args(x):\n",
    "    return x.GetID(), thetraits(x), x\n",
    "\n",
    "# called to display the new winner\n",
    "def onimpr(pop, hof):\n",
    "    try:\n",
    "        print(thetraits(hof[-1]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if genetic_search_on:\n",
    "    run_name = uuname()\n",
    "\n",
    "    g = NEAT.Genome(0, 1, 1, 1, \n",
    "                    0, NEAT.ActivationFunction.TANH,\n",
    "                    NEAT.ActivationFunction.TANH, 0, params, 0)\n",
    "    pop = NEAT.Population(g, params, True, 1.0, rnd.randint(0, 1000))\n",
    "\n",
    "    #%%pixie_debugger\n",
    "\n",
    "    evhist, hof = run_NEAT_loop(pop, num_generations=num_generations, \n",
    "                       num_evaluations=max_evaluations, \n",
    "                       parallel=0, rc=0, lbview = 0, generational_mode=generational_mode, \n",
    "                       evaluator=evaluate_genome, \n",
    "                       evaluator_args=eval_args, \n",
    "                       callback_on_improvement= onimpr\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if genetic_search_on:\n",
    "    run_name = uuname()\n",
    "\n",
    "    g = NEAT.Genome(0, 1, 1, 1, \n",
    "                    0, NEAT.ActivationFunction.TANH,\n",
    "                    NEAT.ActivationFunction.TANH, 0, params, 0)\n",
    "    pop = NEAT.Population(g, params, True, 1.0, rnd.randint(0, 1000))\n",
    "\n",
    "    #%%pixie_debugger\n",
    "\n",
    "    evhist2, hof2 = run_NEAT_loop(pop, num_generations=num_generations, \n",
    "                       num_evaluations=max_evaluations, \n",
    "                       parallel=0, rc=0, lbview = 0, generational_mode=generational_mode, \n",
    "                       evaluator=evaluate_genome_regular, \n",
    "                       evaluator_args=eval_args, \n",
    "                       callback_on_improvement= onimpr\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tests, reduce num_trials to 1\n",
    "onum_trials = num_trials\n",
    "num_trials = 1\n",
    "datasplit_mode='random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# get results from the vote retrained from scratch\n",
    "def get_voting_preds(prep, stack, slc, dx, dy, weights=None):\n",
    "    np.random.seed()\n",
    "    preps = [prep]\n",
    "    # The preprocessed data \n",
    "    dpx = {}\n",
    "    dpxv = {}\n",
    "    dpy = {}\n",
    "    dpyv = {}\n",
    "    \n",
    "    mdpx = {}\n",
    "    mdpxv = {}\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        data_x, x_val, data_y, y_val = datasplit(dx, dy, trial, num_trials=num_trials, test_size=test_size, mode=datasplit_mode)\n",
    "        #if prediction_mode != 'regression':\n",
    "          #  data_y.shape = -1, 1\n",
    "           # y_val.shape = -1, 1\n",
    "        dpxt = {}\n",
    "        dpxvt = {}\n",
    "\n",
    "        # Preprocessing\n",
    "        for i,n in enumerate(preps):\n",
    "            try:\n",
    "                c = decode_preprocessor(n,{})\n",
    "                c.fit(data_x, data_y)\n",
    "            except:\n",
    "                try:\n",
    "                    c.fit(data_x)\n",
    "                except:\n",
    "                    pass\n",
    "            try:\n",
    "                dpxt[n] = c.transform( data_x )\n",
    "                dpxvt[n] = c.transform( x_val )\n",
    "            except:\n",
    "                dpxt[n] = data_x\n",
    "                dpxvt[n] = x_val\n",
    "            \n",
    "        dpx[trial] = dpxt\n",
    "        dpxv[trial] = dpxvt \n",
    "        dpy[trial] = data_y\n",
    "        dpyv[trial] = y_val\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        #mdpx[trial] = {}\n",
    "        mdpxv[trial] = {}\n",
    "        for pn in preps:\n",
    "            #mdpx[trial][pn] = {}\n",
    "            mdpxv[trial][pn] = {}\n",
    "            for n in stack:\n",
    "                # fit classifier on data\n",
    "                c = mappings[prediction_mode](n,prediction_mode)\n",
    "                try:\n",
    "                    c.fit(dpx[trial][pn], dpy[trial])\n",
    "                    #mdpx[trial][pn][n] = predictor(c, prediction_mode)( dpx[trial][pn] )\n",
    "                    mdpxv[trial][pn][n] = predictor(c, prediction_mode)( dpxv[trial][pn] )\n",
    "                except:\n",
    "                    #mdpx[trial][pn][n] = dpx[trial][pn]\n",
    "                    mdpxv[trial][pn][n] = dpxv[trial][pn]\n",
    "    accs=[]\n",
    "        \n",
    "    for trial in range(num_trials):\n",
    "        # get predictions for x\n",
    "        am = [mdpxv[trial][prep][n] for n in stack]\n",
    "        a = voting_mixer(am, weights, prediction_mode)        \n",
    "        a = afterprocessing_mapping[prediction_mode](a)\n",
    "            \n",
    "        accs.append( metric_mapping[prediction_mode](dpyv[trial], a) )\n",
    "\n",
    "    return mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     21
    ]
   },
   "outputs": [],
   "source": [
    "# get results from the vote retrained from scratch\n",
    "def get_voting_preds_new(prep, stack, slc, dx, dy, x_val_real, weights=None):\n",
    "    np.random.seed()\n",
    "    preps = [prep]\n",
    "    # The preprocessed data \n",
    "    dpx = {}\n",
    "    dpxv = {}\n",
    "    dpy = {}\n",
    "    dpyv = {}\n",
    "    \n",
    "    #mdpx = {}\n",
    "    mdpxv = {}\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        data_x, x_val, data_y, y_val = dx, x_val_real, dy, None\n",
    "        #if prediction_mode != 'regression':\n",
    "        #    data_y.shape = -1, 1\n",
    "        \n",
    "        dpxt = {}\n",
    "        dpxvt = {}\n",
    "\n",
    "        if use_preps:\n",
    "            # Preprocessing\n",
    "            for i,n in enumerate(preps):\n",
    "                try:\n",
    "                    c = decode_preprocessor(n,{})\n",
    "                    c.fit(data_x, data_y)\n",
    "                except:\n",
    "                    try:\n",
    "                        c.fit(data_x)\n",
    "                    except:\n",
    "                        pass\n",
    "                try:\n",
    "                    dpxt[n] = c.transform( data_x )\n",
    "                    dpxvt[n] = c.transform( x_val )\n",
    "                except:\n",
    "                    dpxt[n] = data_x\n",
    "                    dpxvt[n] = x_val\n",
    "\n",
    "        else:\n",
    "            dpxt['Raw'] = data_x\n",
    "            dpxvt['Raw'] = x_val\n",
    "            \n",
    "        dpx[trial] = dpxt\n",
    "        dpxv[trial] = dpxvt \n",
    "        dpy[trial] = data_y\n",
    "        dpyv[trial] = y_val\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        #mdpx[trial] = {}\n",
    "        mdpxv[trial] = {}\n",
    "\n",
    "        for pn in preps:\n",
    "            #mdpx[trial][pn] = {}\n",
    "            mdpxv[trial][pn] = {}\n",
    "\n",
    "            for n in stack:\n",
    "                # fit classifier on data\n",
    "                c = mappings[prediction_mode](n,prediction_mode)\n",
    "                try:\n",
    "                    c.fit(dpx[trial][pn], dpy[trial])\n",
    "                    #mdpx[trial][pn][n] = predictor(c, prediction_mode)( dpx[trial][pn] )\n",
    "                    mdpxv[trial][pn][n] = predictor(c, prediction_mode)( dpxv[trial][pn] )\n",
    "                except:\n",
    "                    #mdpx[trial][pn][n] = dpx[trial][pn]\n",
    "                    mdpxv[trial][pn][n] = dpxv[trial][pn]\n",
    "    pds=[]\n",
    "        \n",
    "    for trial in range(num_trials):\n",
    "        # get predictions for x\n",
    "        am = [mdpxv[trial][prep][n] for n in stack]\n",
    "        a = voting_mixer(am, weights, prediction_mode)\n",
    "        a = afterprocessing_mapping[prediction_mode](a)\n",
    "        pds.append(a) \n",
    "\n",
    "    return np.mean(array(pds), axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# get results from the stack retrained from scratch\n",
    "def get_stack_preds(prep, stack, slc, dx, dy):\n",
    "    preps = [prep]\n",
    "    # The preprocessed data \n",
    "    dpx = {}\n",
    "    dpxv = {}\n",
    "    dpy = {}\n",
    "    dpyv = {}\n",
    "    \n",
    "    mdpx = {}\n",
    "    mdpxv = {}\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        data_x, x_val, data_y, y_val = datasplit(dx, dy, trial, num_trials=num_trials, test_size=test_size, mode=datasplit_mode)\n",
    "        #if prediction_mode != 'regression':\n",
    "           # data_y.shape = -1, 1\n",
    "            #y_val.shape = -1, 1\n",
    "        dpxt = {}\n",
    "        dpxvt = {}\n",
    "        \n",
    "        # Preprocessing\n",
    "        if use_preps:\n",
    "            for i,n in enumerate(preps):\n",
    "                try:\n",
    "                    c = decode_preprocessor(n,{})\n",
    "                    c.fit(data_x, data_y)\n",
    "                except:\n",
    "                    try:\n",
    "                        c.fit(data_x)\n",
    "                    except:\n",
    "                        pass\n",
    "                try:\n",
    "                    dpxt[n] = c.transform( data_x )\n",
    "                    dpxvt[n] = c.transform( x_val )\n",
    "                except:\n",
    "                    dpxt[n] = data_x\n",
    "                    dpxvt[n] = x_val\n",
    "                dpyt[n] = data_y\n",
    "                dpyvt[n] = y_val\n",
    "        else:\n",
    "            dpxt['Raw'] = data_x\n",
    "            dpxvt['Raw'] = x_val\n",
    "            \n",
    "        dpx[trial] = dpxt\n",
    "        dpxv[trial] = dpxvt \n",
    "        dpy[trial] = data_y\n",
    "        dpyv[trial] = y_val\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        mdpx[trial] = {}\n",
    "        mdpxv[trial] = {}\n",
    "\n",
    "        for pn in preps:\n",
    "            mdpx[trial][pn] = {}\n",
    "            mdpxv[trial][pn] = {}\n",
    "\n",
    "            for n in stack:\n",
    "                # fit classifier on data\n",
    "                c = mappings[prediction_mode](n,prediction_mode)\n",
    "                    \n",
    "                try:\n",
    "                    c.fit(dpx[trial][pn], dpy[trial])\n",
    "                    mdpx[trial][pn][n] = predictor(c, prediction_mode)( dpx[trial][pn] )\n",
    "                    mdpxv[trial][pn][n] = predictor(c, prediction_mode)( dpxv[trial][pn] )\n",
    "                except:\n",
    "                    mdpx[trial][pn][n] = dpx[trial][pn]\n",
    "                    mdpxv[trial][pn][n] = dpxv[trial][pn]\n",
    "\n",
    "        \n",
    "    accs=[]\n",
    "        \n",
    "    for trial in range(num_trials):\n",
    "        # get predictions for x\n",
    "        if prediction_mode!='multiclass_classification':\n",
    "            am = [mdpx[trial][prep][n].reshape(-1,1) for n in stack]\n",
    "            if stack_original_level1:\n",
    "                am.append( dpx[trial]['Raw'].reshape(-1,1) )\n",
    "        else:\n",
    "            am = [mdpx[trial][prep][n] for n in stack]\n",
    "            if stack_original_level1:\n",
    "                am.append( dpx[trial]['Raw'] )\n",
    "        am = hstack(am)\n",
    "        # train the second level classifier on the predictions \n",
    "        clf = mappings_2nd_level[prediction_mode](n,prediction_mode)\n",
    "        clf.fit(am, dpy[trial])\n",
    "        # now predict on the validation set\n",
    "        # get the individual classifier predictions, stack them, get the second level prediction\n",
    "        if prediction_mode!='multiclass_classification':\n",
    "            ps = [mdpxv[trial][prep][n].reshape(-1,1) for n in stack]\n",
    "            if stack_original_level1:\n",
    "                ps.append( dpxv[trial]['Raw'].reshape(-1,1) )\n",
    "        else:\n",
    "            ps = [mdpxv[trial][prep][n] for n in stack]\n",
    "            if stack_original_level1:\n",
    "                ps.append( dpxv[trial]['Raw'] )\n",
    "        ps = hstack(ps)\n",
    "        a = clf.predict(ps)\n",
    "        a = a.astype(np.float)\n",
    "        a = afterprocessing_mapping[prediction_mode](a)\n",
    "        accs.append( metric_mapping[prediction_mode](dpyv[trial], a) )\n",
    "\n",
    "    return mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# get results from the stack retrained from scratch\n",
    "def get_stack_preds_new(prep, stack, slc, dx, dy, x_val_real):\n",
    "    preps = [prep]\n",
    "    # The preprocessed data \n",
    "    dpx = {}\n",
    "    dpxv = {}\n",
    "    dpy = {}\n",
    "    dpyv = {}\n",
    "    \n",
    "    mdpx = {}\n",
    "    mdpxv = {}\n",
    "    \n",
    "    for trial in range(num_trials):\n",
    "        data_x, x_val, data_y, y_val = dx, x_val_real, dy, None\n",
    "        #if prediction_mode != 'regression':\n",
    "        #    data_y.shape = -1, 1\n",
    "        dpxt = {}\n",
    "        dpxvt = {}\n",
    "        # Preprocessing\n",
    "        if use_preps:\n",
    "            for i,n in enumerate(preps):\n",
    "                try:\n",
    "                    c = decode_preprocessor(n,{})\n",
    "                    c.fit(data_x, data_y)\n",
    "                except:\n",
    "                    try:\n",
    "                        c.fit(data_x)\n",
    "                    except:\n",
    "                        pass\n",
    "                try:\n",
    "                    dpxt[n] = c.transform( data_x )\n",
    "                    dpxvt[n] = c.transform( x_val )\n",
    "                except:\n",
    "                    dpxt[n] = data_x\n",
    "                    dpxvt[n] = x_val\n",
    "        else:\n",
    "            dpxt['Raw'] = data_x\n",
    "            dpxvt['Raw'] = x_val\n",
    "\n",
    "        dpx[trial] = dpxt\n",
    "        dpxv[trial] = dpxvt \n",
    "        dpy[trial] = data_y\n",
    "        dpyv[trial] = y_val\n",
    "\n",
    "    for trial in range(num_trials):\n",
    "        mdpx[trial] = {}\n",
    "        mdpxv[trial] = {}\n",
    "\n",
    "        for pn in preps:\n",
    "            mdpx[trial][pn] = {}\n",
    "            mdpxv[trial][pn] = {}\n",
    "\n",
    "            for n in stack:\n",
    "                # fit classifier on data\n",
    "                c = mappings[prediction_mode](n,prediction_mode)\n",
    "                    \n",
    "                try:\n",
    "                    c.fit(dpx[trial][pn], dpy[trial])\n",
    "                    mdpx[trial][pn][n] = predictor( c, prediction_mode) (dpx[trial][pn] )\n",
    "                    mdpxv[trial][pn][n] = predictor( c, prediction_mode) ( dpxv[trial][pn] )\n",
    "                except:\n",
    "                    mdpx[trial][pn][n] = dpx[trial][pn]\n",
    "                    mdpxv[trial][pn][n] = dpxv[trial][pn]\n",
    "        \n",
    "    pds=[]\n",
    "        \n",
    "    for trial in range(num_trials):\n",
    "        # get predictions for x\n",
    "        if prediction_mode!='multiclass_classification':\n",
    "            am = [mdpx[trial][prep][n].reshape(-1,1) for n in stack]\n",
    "            if stack_original_level1:\n",
    "                am.append( dpx[trial]['Raw'].reshape(-1,1) )\n",
    "        else:\n",
    "            am = [mdpx[trial][prep][n] for n in stack]\n",
    "            if stack_original_level1:\n",
    "                am.append( dpx[trial]['Raw'] )\n",
    "        am = hstack(am)\n",
    "        # train the second level classifier on the predictions\n",
    "        clf = mappings_2nd_level[prediction_mode](n,prediction_mode)\n",
    "        clf.fit(am, dpy[trial])\n",
    "        # now predict on the validation set\n",
    "        # get the individual classifier predictions, stack them, get the second level prediction\n",
    "        if prediction_mode!='multiclass_classification':\n",
    "            ps = [mdpxv[trial][prep][n].reshape(-1,1) for n in stack]\n",
    "            if stack_original_level1:\n",
    "                ps.append( dpxv[trial]['Raw'].reshape(-1,1) )\n",
    "        else:\n",
    "            ps = [mdpxv[trial][prep][n] for n in stack]\n",
    "            if stack_original_level1:\n",
    "                ps.append( dpxv[trial]['Raw'] )\n",
    "        ps = hstack(ps)\n",
    "        a = clf.predict(ps)\n",
    "        a = a.astype(np.float).reshape(-1)\n",
    "        a = afterprocessing_mapping[prediction_mode](a)\n",
    "        pds.append(a)\n",
    "\n",
    "    return np.mean(array(pds), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test stacking"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "try:\n",
    "    p, m, sl = sorted(allr, key=lambda x: x[0], reverse=True)[0][-3:]\n",
    "except:\n",
    "    ts = hof[-1].GetGenomeTraits()['x']\n",
    "    m, p, sl = ts.cltypes, ts.pp, ts.slc    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test it lots of times\n",
    "print(p, m, sl)\n",
    "times = 100\n",
    "acs = []\n",
    "for i in range(times):\n",
    "    print(i,'/',times,' '*10, end='\\r')\n",
    "    a = get_stack_preds(p, m, sl, dx, dy)\n",
    "    a = float(a)\n",
    "    acs.append( a )\n",
    "    \n",
    "\n",
    "mean(acs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist(acs, 30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test voting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "try:\n",
    "    p, m,  = sorted(allr2, key=lambda x: x[0], reverse=True)[0][-2:]\n",
    "    sl = None\n",
    "except:\n",
    "    ts = hof2[-1].GetGenomeTraits()['x']\n",
    "    m, p, sl = ts.cltypes, ts.pp, ts.slc    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# test it lots of times\n",
    "print(p, m, sl)\n",
    "times = 100\n",
    "if parallel:\n",
    "    pass\n",
    "else:\n",
    "    acs = []\n",
    "    for i in range(times):\n",
    "        print(i,'/',times,' '*10, end='\\r')\n",
    "        a = get_voting_preds(p, m, sl, dx, dy)\n",
    "        a = float(a)\n",
    "        acs.append( a )\n",
    "mean(acs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hist(acs, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the data\n",
    "print(dx.shape, dy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape of the data used to make Kaggle predictions\n",
    "print(x_val_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions to Kaggle from stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if prediction_mode == 'regression':\n",
    "        p, m, sl = sorted(allr, key=lambda x: x[0], reverse=False)[0][-3:]\n",
    "    else:\n",
    "        p, m, sl = sorted(allr, key=lambda x: x[0], reverse=True)[0][-3:]\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "    ts = hof[-1].GetGenomeTraits()['x']\n",
    "    m, p, sl = ts.cltypes, ts.pp, ts.slc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "#%%pixie_debugger\n",
    "\n",
    "# Compute predictions for Kaggle and bag them \n",
    "times=1\n",
    "pcs = []\n",
    "for i in range(times):\n",
    "    print(i,'/',times,' '*10, end='\\r')\n",
    "    a = get_stack_preds_new(p, m, sl, dx, dy, x_val_real)\n",
    "    pcs.append( a )\n",
    "\n",
    "print(p, m, sl)\n",
    "pc = mean(array(pcs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_titanic:\n",
    "    if titanic_version == 1:\n",
    "        sub = pd.DataFrame()\n",
    "        sub['PassengerId'] = p_id\n",
    "        sub['Survived'] = pc.astype(int)\n",
    "        sub.to_csv('Titanic_Submissions_Stack.csv', index=False)\n",
    "    elif titanic_version == 2:\n",
    "        probs = pc.astype(int)\n",
    "        results = pd.DataFrame(probs, columns = ['Survived'])\n",
    "        results['PassengerId'] = list(pd.read_csv('titanic_test.csv')['PassengerId'])\n",
    "        (results[['PassengerId', 'Survived']]\n",
    "            .to_csv('Titanic_Submissions_Stack.csv', index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_gacrp:\n",
    "    from loaders.gacrp import df_test\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    def rmse(y_true, y_pred):\n",
    "        return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n",
    "\n",
    "    def submit():\n",
    "        test_matrix = x_val_real\n",
    "        y_pred = pc#model.predict(test_matrix, verbose=1)\n",
    "        df_test['PredictedLogRevenue'] = y_pred\n",
    "        submit = df_test[['PredictedLogRevenue','fullVisitorId']].groupby('fullVisitorId').PredictedLogRevenue.sum().reset_index()\n",
    "        submit.to_csv('submit_stacking.csv',index=False)\n",
    "\n",
    "        test(y_pred)\n",
    "\n",
    "    def test(predict):\n",
    "        y_test = np.log1p(df_test['totals_transactionRevenue'])\n",
    "        print(rmse(y_test,predict))\n",
    "        \n",
    "    submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_elo:\n",
    "    predictions = pc\n",
    "    results = pd.DataFrame(predictions, columns = ['target'])\n",
    "    if socket.gethostname() == 'desktop':\n",
    "        results['card_id'] = list(pd.read_csv('/home/peter/code/work/automl/data/elo/sample_submission.csv')['card_id'])\n",
    "    else:\n",
    "        results['card_id'] = list(pd.read_csv('/home/ubuntu/new/automl/elo/sample_submission.csv')['card_id'])\n",
    "    (results[['card_id', 'target']]\n",
    "        .to_csv('ELO_automl_stack1_no_outliers.csv', index = False))\n",
    "    print(\"created submissions file named ELO_automl_stack1.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions to Kaggle from voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if prediction_mode == 'regression':\n",
    "        p, m, ws = sorted(allr2, key=lambda x: x[0], reverse=False)[0][-3:]\n",
    "    else:\n",
    "        p, m, ws = sorted(allr2, key=lambda x: x[0], reverse=True)[0][-3:]\n",
    "    sl = None\n",
    "except:\n",
    "    ts = hof2[-1].GetGenomeTraits()['x']\n",
    "    m, p, sl = ts.cltypes, ts.pp, ts.slc\n",
    "    ws=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions for Kaggle and bag them \n",
    "times=1\n",
    "pcs = []\n",
    "for i in range(times):\n",
    "    print(i,'/',times,' '*10, end='\\r')\n",
    "    a = get_voting_preds_new(p, m, sl, dx, dy, x_val_real, weights=ws)\n",
    "    pcs.append( a )\n",
    "\n",
    "print(p, m, sl)\n",
    "pc = mean(array(pcs), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_titanic:\n",
    "    if titanic_version == 1:\n",
    "        sub = pd.DataFrame()\n",
    "        sub['PassengerId'] = p_id\n",
    "        sub['Survived'] = np.round(pc).astype(int)\n",
    "        sub.to_csv('Titanic_Submissions_Vote.csv', index=False)\n",
    "    elif titanic_version == 2:\n",
    "        probs = np.round(pc).astype(int)\n",
    "        results = pd.DataFrame(probs, columns = ['Survived'])\n",
    "        results['PassengerId'] = list(pd.read_csv('titanic_test.csv')['PassengerId'])\n",
    "        (results[['PassengerId', 'Survived']]\n",
    "            .to_csv('Titanic_Submissions_Vote.csv', index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_gacrp:\n",
    "    from loaders.gacrp import df_test\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    def rmse(y_true, y_pred):\n",
    "        return round(np.sqrt(mean_squared_error(y_true, y_pred)), 5)\n",
    "\n",
    "    def submit():\n",
    "        test_matrix = x_val_real\n",
    "        y_pred = pc#model.predict(test_matrix, verbose=1)\n",
    "        df_test['PredictedLogRevenue'] = y_pred\n",
    "        submit = df_test[['PredictedLogRevenue','fullVisitorId']].groupby('fullVisitorId').PredictedLogRevenue.sum().reset_index()\n",
    "        submit.to_csv('submit_voting.csv',index=False)\n",
    "\n",
    "        test(y_pred)\n",
    "\n",
    "    def test(predict):\n",
    "        y_test = np.log1p(df_test['totals_transactionRevenue'])\n",
    "        print(rmse(y_test,predict))\n",
    "        \n",
    "    submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_elo:\n",
    "    predictions = pc\n",
    "    results = pd.DataFrame(predictions, columns = ['target'])\n",
    "    if socket.gethostname() == 'desktop':\n",
    "        results['card_id'] = list(pd.read_csv('/home/peter/code/work/automl/data/elo/sample_submission.csv')['card_id'])\n",
    "    else:\n",
    "        results['card_id'] = list(pd.read_csv('/home/ubuntu/new/automl/elo/sample_submission.csv')['card_id'])\n",
    "    (results[['card_id', 'target']]\n",
    "        .to_csv('ELO_automl_vote1_no_outliers.csv', index = False))\n",
    "    print(\"created submissions file named ELO_automl_vote1.csv\") "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a=PCA(n_components=2).fit_transform(pcs)\n",
    "plot(a[:,0],a[:,1],'ro');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "170px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
