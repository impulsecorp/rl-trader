{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cuDNN version 5110 on context None\n",
      "Mapped name None to device cuda: GeForce GTX 950M (0000:01:00.0)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "os.environ['THEANO_FLAGS'] = 'mode=FAST_RUN,device=cuda,floatX=float32,nvcc.flags=-arch=sm_35'\n",
    "sys.path.append(\"/root\")\n",
    "sys.path.append(\"/home/peter\")\n",
    "sys.path.append(\"/home/peter/Desktop\")\n",
    "sys.path.append(\"/home/peter/Desktop/projects\")\n",
    "sys.path.append(\"/home/peter/Desktop/work\")\n",
    "sys.path.append(\"/home/peter/code/projects\")\n",
    "sys.path.append(\"/home/peter/code/work\")\n",
    "sys.path.append(\"/home/peter/code/common\")\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, IntSlider, FloatSlider\n",
    "from IPython.display import clear_output, display, HTML\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pickle as pkl\n",
    "from sklearn import linear_model\n",
    "from sklearn.decomposition import PCA\n",
    "import random as rnd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import theano.tensor as T\n",
    "import theano as th\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import RepeatVector, Reshape, Permute, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.layers.local import LocallyConnected1D\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.optimizers import SGD, Adadelta, Adamax, Adagrad, Adam, RMSprop, Nadam, TFOptimizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import cymysql as sql\n",
    "import pandas as pd\n",
    "import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_source = np.load(open('data_spy.npy','rb'))\n",
    "tgt = np.load(open('data_spy_targets.npy','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "to_predict = tgt[3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "input_source = input_source[0:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "winlen = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sliding_window_jump = 1\n",
    "predict_time_ahead = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_partitioned_counts(cl, rr, rt):\n",
    "    \" data, steps_forward, partition_num\"\n",
    "    cl = cl[rr:] - cl[0:-rr]\n",
    "    cl = hstack([[0]*rr, cl])\n",
    "    pdown = len(cl[cl < -rt])\n",
    "    pup = len(cl[cl > rt])\n",
    "    pmid = len(cl[(cl <= rt) & (cl >= -rt)])\n",
    "    return pup, pmid, pdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def partition_data_num(cl, predict_ahead):\n",
    "    a=[]\n",
    "    b=[]\n",
    "    c=[]\n",
    "    ts = np.linspace(0.0, 1.0, 10000)\n",
    "    for x in ts:\n",
    "        au, am, ad = get_partitioned_counts(cl, predict_ahead, x)\n",
    "        a.append(au)\n",
    "        b.append(am)\n",
    "        c.append(ad)\n",
    "    a, b, c = array(a), array(b), array(c)\n",
    "    return ts[np.argmin(np.abs(a-b) + np.abs(a-c) + np.abs(b-c))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277000/277890)\n",
      "Ups: 100613 Mids: 77973 Downs: 99204\n",
      "Separator: 0.01000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create training set\n",
    "sep = partition_data_num(to_predict, predict_time_ahead)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "ups = []\n",
    "downs = []\n",
    "mids = []\n",
    "\n",
    "for i in range(0, input_source.shape[1]-(winlen+100), sliding_window_jump):\n",
    "    # form the input\n",
    "    xs = input_source[:, i:i+winlen]\n",
    "    #xs = scale(xs, axis=1)\n",
    "    xs = xs.ravel()\n",
    "\n",
    "    # for the output\n",
    "    now = to_predict[i+winlen-1].ravel() # close\n",
    "    future = to_predict[i+winlen+(predict_time_ahead-1)].ravel() # next close\n",
    "\n",
    "    ys = future-now\n",
    "    magn = abs(ys)\n",
    "\n",
    "    if magn < sep:\n",
    "        mids.append( (xs, np.array([0, 1, 0])) )\n",
    "    else:\n",
    "        if ys < 0:\n",
    "            downs.append( (xs, np.array([0, 0, 1])) )\n",
    "        else:\n",
    "            ups.append( (xs, np.array([1, 0, 0])) )\n",
    "\n",
    "    if (i%1000)==0:\n",
    "        clear_output(wait=True)\n",
    "        print('({}/{})'.format(i, input_source.shape[1]-winlen))\n",
    "\n",
    "print('Ups: {0} Mids: {1} Downs: {2}'.format(len(ups), len(mids), len(downs)))\n",
    "print('Separator: %3.5f' % sep)\n",
    "print()\n",
    "\n",
    "samplesize = min(len(ups), len(downs), len(mids))\n",
    "s1 = rnd.sample(ups, samplesize)\n",
    "s2 = rnd.sample(downs, samplesize)\n",
    "s3 = rnd.sample(mids, samplesize)\n",
    "a = s1 + s2 + s3\n",
    "rnd.shuffle(a)\n",
    "x = [x[0] for x in a]\n",
    "y = [x[1] for x in a]\n",
    "\n",
    "x = np.vstack(x)\n",
    "y = np.vstack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((233919, 172), (233919, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x.shape = (x.shape[0], -1, winlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(233919, 172, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH8AAAOfCAYAAADhERwMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8baf256c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matshow(x[10]); colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cutpoint = int(0.8 * x.shape[0])\n",
    "x_train = x[0:cutpoint]\n",
    "x_test = x[cutpoint:]\n",
    "y_train = y[0:cutpoint]\n",
    "y_test = y[cutpoint:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Flatten( input_shape=(x.shape[1], winlen) ))\n",
    "\n",
    "model.add(Dense(80, init='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(80, init='uniform'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.8))\n",
    "\n",
    "model.add(Dense(40, init='uniform'))\n",
    "model.add(Activation('tanh'))\n",
    "    \n",
    "model.add(Dropout(0.4))\n",
    "    \n",
    "model.add(Dense(3))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = Adamax()#(lr=0.001, rho=0.9, epsilonAGE=1e-6)\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=sgd,\n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "pred = model.predict(x_test, batch_size=50)\n",
    "pred.shape = (-1)\n",
    "pred[pred < 0] = -1\n",
    "pred[pred > 0] = 1\n",
    "\n",
    "percent_correct = sum(pred == y_test.reshape(-1)) / len(pred)\n",
    "percent_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33143809849521205"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test, batch_size=50)\n",
    "corr = sum(argmax(pred, axis=1) == argmax(y_test, axis=1)) / pred.shape[0]\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 187135 samples, validate on 46784 samples\n",
      "Epoch 1/1000\n",
      "0s - loss: 0.1097 - acc: 0.3359 - val_loss: 0.1064 - val_acc: 0.3764\n",
      "Epoch 2/1000\n",
      "0s - loss: 0.1070 - acc: 0.3581 - val_loss: 0.1049 - val_acc: 0.4077\n",
      "Epoch 3/1000\n",
      "0s - loss: 0.1061 - acc: 0.3818 - val_loss: 0.1044 - val_acc: 0.4108\n",
      "Epoch 4/1000\n",
      "0s - loss: 0.1056 - acc: 0.3905 - val_loss: 0.1040 - val_acc: 0.4162\n",
      "Epoch 5/1000\n",
      "0s - loss: 0.1054 - acc: 0.3953 - val_loss: 0.1039 - val_acc: 0.4158\n",
      "Epoch 6/1000\n",
      "0s - loss: 0.1051 - acc: 0.4001 - val_loss: 0.1038 - val_acc: 0.4175\n",
      "Epoch 7/1000\n",
      "0s - loss: 0.1050 - acc: 0.4007 - val_loss: 0.1037 - val_acc: 0.4183\n",
      "Epoch 8/1000\n",
      "0s - loss: 0.1049 - acc: 0.4032 - val_loss: 0.1037 - val_acc: 0.4195\n",
      "Epoch 9/1000\n",
      "0s - loss: 0.1047 - acc: 0.4060 - val_loss: 0.1035 - val_acc: 0.4149\n",
      "Epoch 10/1000\n",
      "0s - loss: 0.1048 - acc: 0.4039 - val_loss: 0.1036 - val_acc: 0.4173\n",
      "Epoch 11/1000\n",
      "0s - loss: 0.1047 - acc: 0.4044 - val_loss: 0.1036 - val_acc: 0.4181\n",
      "Epoch 12/1000\n",
      "0s - loss: 0.1046 - acc: 0.4047 - val_loss: 0.1035 - val_acc: 0.4152\n",
      "Epoch 13/1000\n",
      "0s - loss: 0.1046 - acc: 0.4036 - val_loss: 0.1036 - val_acc: 0.4089\n",
      "Epoch 14/1000\n",
      "0s - loss: 0.1045 - acc: 0.4038 - val_loss: 0.1035 - val_acc: 0.4115\n",
      "Epoch 15/1000\n",
      "0s - loss: 0.1044 - acc: 0.4043 - val_loss: 0.1033 - val_acc: 0.4133\n",
      "Epoch 16/1000\n",
      "0s - loss: 0.1044 - acc: 0.4047 - val_loss: 0.1034 - val_acc: 0.4185\n",
      "Epoch 17/1000\n",
      "0s - loss: 0.1044 - acc: 0.4046 - val_loss: 0.1034 - val_acc: 0.4161\n",
      "Epoch 18/1000\n",
      "0s - loss: 0.1043 - acc: 0.4047 - val_loss: 0.1034 - val_acc: 0.4193\n",
      "Epoch 19/1000\n",
      "0s - loss: 0.1043 - acc: 0.4057 - val_loss: 0.1034 - val_acc: 0.4157\n",
      "Epoch 20/1000\n",
      "0s - loss: 0.1043 - acc: 0.4048 - val_loss: 0.1033 - val_acc: 0.4188\n",
      "Epoch 21/1000\n",
      "0s - loss: 0.1042 - acc: 0.4074 - val_loss: 0.1034 - val_acc: 0.4182\n",
      "Epoch 22/1000\n",
      "0s - loss: 0.1042 - acc: 0.4078 - val_loss: 0.1033 - val_acc: 0.4135\n",
      "Epoch 23/1000\n",
      "0s - loss: 0.1042 - acc: 0.4076 - val_loss: 0.1033 - val_acc: 0.4182\n",
      "Epoch 24/1000\n",
      "0s - loss: 0.1041 - acc: 0.4077 - val_loss: 0.1032 - val_acc: 0.4191\n",
      "Epoch 25/1000\n",
      "0s - loss: 0.1041 - acc: 0.4079 - val_loss: 0.1032 - val_acc: 0.4200\n",
      "Epoch 26/1000\n",
      "0s - loss: 0.1041 - acc: 0.4086 - val_loss: 0.1031 - val_acc: 0.4201\n",
      "Epoch 27/1000\n",
      "0s - loss: 0.1040 - acc: 0.4098 - val_loss: 0.1032 - val_acc: 0.4199\n",
      "Epoch 28/1000\n",
      "0s - loss: 0.1041 - acc: 0.4093 - val_loss: 0.1031 - val_acc: 0.4203\n",
      "Epoch 29/1000\n",
      "0s - loss: 0.1040 - acc: 0.4098 - val_loss: 0.1031 - val_acc: 0.4217\n",
      "Epoch 30/1000\n",
      "0s - loss: 0.1040 - acc: 0.4096 - val_loss: 0.1031 - val_acc: 0.4213\n",
      "Epoch 31/1000\n",
      "0s - loss: 0.1040 - acc: 0.4099 - val_loss: 0.1031 - val_acc: 0.4207\n",
      "Epoch 32/1000\n",
      "0s - loss: 0.1039 - acc: 0.4117 - val_loss: 0.1030 - val_acc: 0.4213\n",
      "Epoch 33/1000\n",
      "0s - loss: 0.1039 - acc: 0.4116 - val_loss: 0.1030 - val_acc: 0.4204\n",
      "Epoch 34/1000\n",
      "0s - loss: 0.1039 - acc: 0.4111 - val_loss: 0.1031 - val_acc: 0.4214\n",
      "Epoch 35/1000\n",
      "0s - loss: 0.1038 - acc: 0.4103 - val_loss: 0.1031 - val_acc: 0.4209\n",
      "Epoch 36/1000\n",
      "0s - loss: 0.1039 - acc: 0.4125 - val_loss: 0.1031 - val_acc: 0.4222\n",
      "Epoch 37/1000\n",
      "0s - loss: 0.1038 - acc: 0.4112 - val_loss: 0.1030 - val_acc: 0.4192\n",
      "Epoch 38/1000\n",
      "0s - loss: 0.1038 - acc: 0.4118 - val_loss: 0.1030 - val_acc: 0.4206\n",
      "Epoch 39/1000\n",
      "0s - loss: 0.1038 - acc: 0.4121 - val_loss: 0.1030 - val_acc: 0.4218\n",
      "Epoch 40/1000\n",
      "0s - loss: 0.1038 - acc: 0.4123 - val_loss: 0.1029 - val_acc: 0.4217\n",
      "Epoch 41/1000\n",
      "0s - loss: 0.1037 - acc: 0.4138 - val_loss: 0.1031 - val_acc: 0.4216\n",
      "Epoch 42/1000\n",
      "1s - loss: 0.1038 - acc: 0.4119 - val_loss: 0.1030 - val_acc: 0.4207\n",
      "Epoch 43/1000\n",
      "0s - loss: 0.1037 - acc: 0.4130 - val_loss: 0.1029 - val_acc: 0.4222\n",
      "Epoch 44/1000\n",
      "0s - loss: 0.1037 - acc: 0.4122 - val_loss: 0.1030 - val_acc: 0.4219\n",
      "Epoch 45/1000\n",
      "0s - loss: 0.1037 - acc: 0.4113 - val_loss: 0.1029 - val_acc: 0.4225\n",
      "Epoch 46/1000\n",
      "0s - loss: 0.1037 - acc: 0.4136 - val_loss: 0.1029 - val_acc: 0.4210\n",
      "Epoch 47/1000\n",
      "0s - loss: 0.1037 - acc: 0.4144 - val_loss: 0.1028 - val_acc: 0.4228\n",
      "Epoch 48/1000\n",
      "0s - loss: 0.1037 - acc: 0.4140 - val_loss: 0.1029 - val_acc: 0.4213\n",
      "Epoch 49/1000\n",
      "0s - loss: 0.1037 - acc: 0.4136 - val_loss: 0.1029 - val_acc: 0.4226\n",
      "Epoch 50/1000\n",
      "0s - loss: 0.1037 - acc: 0.4143 - val_loss: 0.1029 - val_acc: 0.4223\n",
      "Epoch 51/1000\n",
      "0s - loss: 0.1037 - acc: 0.4143 - val_loss: 0.1029 - val_acc: 0.4223\n",
      "Epoch 52/1000\n",
      "0s - loss: 0.1036 - acc: 0.4140 - val_loss: 0.1028 - val_acc: 0.4227\n",
      "Epoch 53/1000\n",
      "0s - loss: 0.1037 - acc: 0.4149 - val_loss: 0.1030 - val_acc: 0.4228\n",
      "Epoch 54/1000\n",
      "0s - loss: 0.1037 - acc: 0.4157 - val_loss: 0.1028 - val_acc: 0.4223\n",
      "Epoch 55/1000\n",
      "0s - loss: 0.1036 - acc: 0.4143 - val_loss: 0.1028 - val_acc: 0.4235\n",
      "Epoch 56/1000\n",
      "0s - loss: 0.1036 - acc: 0.4148 - val_loss: 0.1028 - val_acc: 0.4223\n",
      "Epoch 57/1000\n",
      "0s - loss: 0.1036 - acc: 0.4140 - val_loss: 0.1028 - val_acc: 0.4222\n",
      "Epoch 58/1000\n",
      "0s - loss: 0.1036 - acc: 0.4148 - val_loss: 0.1029 - val_acc: 0.4219\n",
      "Epoch 59/1000\n",
      "0s - loss: 0.1036 - acc: 0.4164 - val_loss: 0.1028 - val_acc: 0.4225\n",
      "Epoch 60/1000\n",
      "0s - loss: 0.1036 - acc: 0.4171 - val_loss: 0.1028 - val_acc: 0.4223\n",
      "Epoch 61/1000\n",
      "0s - loss: 0.1036 - acc: 0.4164 - val_loss: 0.1028 - val_acc: 0.4223\n",
      "Epoch 62/1000\n",
      "0s - loss: 0.1035 - acc: 0.4164 - val_loss: 0.1029 - val_acc: 0.4213\n",
      "Epoch 63/1000\n",
      "0s - loss: 0.1036 - acc: 0.4150 - val_loss: 0.1028 - val_acc: 0.4230\n",
      "Epoch 64/1000\n",
      "0s - loss: 0.1035 - acc: 0.4147 - val_loss: 0.1028 - val_acc: 0.4231\n",
      "Epoch 65/1000\n",
      "0s - loss: 0.1036 - acc: 0.4158 - val_loss: 0.1028 - val_acc: 0.4233\n",
      "Epoch 66/1000\n",
      "0s - loss: 0.1036 - acc: 0.4149 - val_loss: 0.1027 - val_acc: 0.4225\n",
      "Epoch 67/1000\n",
      "0s - loss: 0.1035 - acc: 0.4163 - val_loss: 0.1028 - val_acc: 0.4224\n",
      "Epoch 68/1000\n",
      "0s - loss: 0.1035 - acc: 0.4157 - val_loss: 0.1027 - val_acc: 0.4225\n",
      "Epoch 69/1000\n",
      "0s - loss: 0.1035 - acc: 0.4150 - val_loss: 0.1027 - val_acc: 0.4228\n",
      "Epoch 70/1000\n",
      "0s - loss: 0.1035 - acc: 0.4148 - val_loss: 0.1029 - val_acc: 0.4221\n",
      "Epoch 71/1000\n",
      "0s - loss: 0.1035 - acc: 0.4152 - val_loss: 0.1029 - val_acc: 0.4224\n",
      "Epoch 72/1000\n",
      "0s - loss: 0.1036 - acc: 0.4166 - val_loss: 0.1029 - val_acc: 0.4219\n",
      "Epoch 73/1000\n",
      "0s - loss: 0.1035 - acc: 0.4153 - val_loss: 0.1028 - val_acc: 0.4233\n",
      "Epoch 74/1000\n",
      "0s - loss: 0.1035 - acc: 0.4165 - val_loss: 0.1027 - val_acc: 0.4226\n",
      "Epoch 75/1000\n",
      "0s - loss: 0.1035 - acc: 0.4162 - val_loss: 0.1028 - val_acc: 0.4226\n",
      "Epoch 76/1000\n",
      "0s - loss: 0.1035 - acc: 0.4167 - val_loss: 0.1028 - val_acc: 0.4233\n",
      "Epoch 77/1000\n",
      "0s - loss: 0.1035 - acc: 0.4166 - val_loss: 0.1028 - val_acc: 0.4225\n",
      "Epoch 78/1000\n",
      "0s - loss: 0.1034 - acc: 0.4174 - val_loss: 0.1029 - val_acc: 0.4225\n",
      "Epoch 79/1000\n",
      "0s - loss: 0.1035 - acc: 0.4165 - val_loss: 0.1027 - val_acc: 0.4233\n",
      "Epoch 80/1000\n",
      "0s - loss: 0.1035 - acc: 0.4156 - val_loss: 0.1029 - val_acc: 0.4221\n",
      "Epoch 81/1000\n",
      "0s - loss: 0.1035 - acc: 0.4167 - val_loss: 0.1028 - val_acc: 0.4235\n",
      "Epoch 82/1000\n",
      "0s - loss: 0.1035 - acc: 0.4177 - val_loss: 0.1029 - val_acc: 0.4226\n",
      "Epoch 83/1000\n",
      "0s - loss: 0.1035 - acc: 0.4171 - val_loss: 0.1028 - val_acc: 0.4241\n",
      "Epoch 84/1000\n",
      "0s - loss: 0.1035 - acc: 0.4173 - val_loss: 0.1027 - val_acc: 0.4232\n",
      "Epoch 85/1000\n",
      "0s - loss: 0.1034 - acc: 0.4166 - val_loss: 0.1028 - val_acc: 0.4233\n",
      "Epoch 86/1000\n",
      "0s - loss: 0.1035 - acc: 0.4166 - val_loss: 0.1027 - val_acc: 0.4238\n",
      "Epoch 87/1000\n",
      "0s - loss: 0.1035 - acc: 0.4164 - val_loss: 0.1028 - val_acc: 0.4238\n",
      "Epoch 88/1000\n",
      "0s - loss: 0.1035 - acc: 0.4171 - val_loss: 0.1028 - val_acc: 0.4228\n",
      "Epoch 89/1000\n",
      "0s - loss: 0.1035 - acc: 0.4165 - val_loss: 0.1027 - val_acc: 0.4229\n",
      "Epoch 90/1000\n",
      "0s - loss: 0.1035 - acc: 0.4171 - val_loss: 0.1028 - val_acc: 0.4238\n",
      "Epoch 91/1000\n",
      "0s - loss: 0.1034 - acc: 0.4182 - val_loss: 0.1026 - val_acc: 0.4236\n",
      "Epoch 92/1000\n",
      "0s - loss: 0.1034 - acc: 0.4164 - val_loss: 0.1028 - val_acc: 0.4235\n",
      "Epoch 93/1000\n",
      "0s - loss: 0.1034 - acc: 0.4171 - val_loss: 0.1027 - val_acc: 0.4240\n",
      "Epoch 94/1000\n",
      "0s - loss: 0.1034 - acc: 0.4157 - val_loss: 0.1028 - val_acc: 0.4239\n",
      "Epoch 95/1000\n",
      "0s - loss: 0.1034 - acc: 0.4176 - val_loss: 0.1027 - val_acc: 0.4232\n",
      "Epoch 96/1000\n",
      "0s - loss: 0.1034 - acc: 0.4170 - val_loss: 0.1028 - val_acc: 0.4238\n",
      "Epoch 97/1000\n",
      "0s - loss: 0.1035 - acc: 0.4170 - val_loss: 0.1027 - val_acc: 0.4241\n",
      "Epoch 98/1000\n",
      "0s - loss: 0.1034 - acc: 0.4169 - val_loss: 0.1026 - val_acc: 0.4241\n",
      "Epoch 99/1000\n",
      "0s - loss: 0.1034 - acc: 0.4171 - val_loss: 0.1026 - val_acc: 0.4239\n",
      "Epoch 100/1000\n",
      "0s - loss: 0.1034 - acc: 0.4172 - val_loss: 0.1027 - val_acc: 0.4236\n",
      "Epoch 101/1000\n",
      "0s - loss: 0.1034 - acc: 0.4183 - val_loss: 0.1027 - val_acc: 0.4233\n",
      "Epoch 102/1000\n",
      "0s - loss: 0.1034 - acc: 0.4184 - val_loss: 0.1028 - val_acc: 0.4217\n",
      "Epoch 103/1000\n",
      "0s - loss: 0.1034 - acc: 0.4198 - val_loss: 0.1027 - val_acc: 0.4234\n",
      "Epoch 104/1000\n",
      "0s - loss: 0.1034 - acc: 0.4179 - val_loss: 0.1027 - val_acc: 0.4225\n",
      "Epoch 105/1000\n",
      "0s - loss: 0.1034 - acc: 0.4177 - val_loss: 0.1028 - val_acc: 0.4240\n",
      "Epoch 106/1000\n",
      "0s - loss: 0.1034 - acc: 0.4190 - val_loss: 0.1026 - val_acc: 0.4245\n",
      "Epoch 107/1000\n",
      "0s - loss: 0.1034 - acc: 0.4183 - val_loss: 0.1027 - val_acc: 0.4223\n",
      "Epoch 108/1000\n",
      "0s - loss: 0.1034 - acc: 0.4184 - val_loss: 0.1027 - val_acc: 0.4223\n",
      "Epoch 109/1000\n",
      "0s - loss: 0.1034 - acc: 0.4169 - val_loss: 0.1026 - val_acc: 0.4244\n",
      "Epoch 110/1000\n",
      "0s - loss: 0.1034 - acc: 0.4175 - val_loss: 0.1028 - val_acc: 0.4235\n",
      "Epoch 111/1000\n",
      "0s - loss: 0.1034 - acc: 0.4175 - val_loss: 0.1026 - val_acc: 0.4230\n",
      "Epoch 112/1000\n",
      "0s - loss: 0.1034 - acc: 0.4163 - val_loss: 0.1027 - val_acc: 0.4223\n",
      "Epoch 113/1000\n",
      "0s - loss: 0.1034 - acc: 0.4176 - val_loss: 0.1027 - val_acc: 0.4243\n",
      "Epoch 114/1000\n",
      "0s - loss: 0.1034 - acc: 0.4190 - val_loss: 0.1027 - val_acc: 0.4248\n",
      "Epoch 115/1000\n",
      "0s - loss: 0.1034 - acc: 0.4179 - val_loss: 0.1028 - val_acc: 0.4243\n",
      "Epoch 116/1000\n",
      "0s - loss: 0.1034 - acc: 0.4169 - val_loss: 0.1026 - val_acc: 0.4204\n",
      "Epoch 117/1000\n",
      "0s - loss: 0.1034 - acc: 0.4176 - val_loss: 0.1027 - val_acc: 0.4237\n",
      "Epoch 118/1000\n",
      "0s - loss: 0.1034 - acc: 0.4166 - val_loss: 0.1026 - val_acc: 0.4235\n",
      "Epoch 119/1000\n",
      "0s - loss: 0.1033 - acc: 0.4185 - val_loss: 0.1026 - val_acc: 0.4240\n",
      "Epoch 120/1000\n",
      "0s - loss: 0.1034 - acc: 0.4182 - val_loss: 0.1026 - val_acc: 0.4239\n",
      "Epoch 121/1000\n",
      "0s - loss: 0.1034 - acc: 0.4184 - val_loss: 0.1027 - val_acc: 0.4233\n",
      "Epoch 122/1000\n",
      "0s - loss: 0.1034 - acc: 0.4188 - val_loss: 0.1026 - val_acc: 0.4241\n",
      "Epoch 123/1000\n",
      "0s - loss: 0.1033 - acc: 0.4178 - val_loss: 0.1027 - val_acc: 0.4250\n",
      "Epoch 124/1000\n",
      "0s - loss: 0.1034 - acc: 0.4178 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 125/1000\n",
      "0s - loss: 0.1033 - acc: 0.4187 - val_loss: 0.1027 - val_acc: 0.4246\n",
      "Epoch 126/1000\n",
      "0s - loss: 0.1034 - acc: 0.4171 - val_loss: 0.1027 - val_acc: 0.4240\n",
      "Epoch 127/1000\n",
      "0s - loss: 0.1033 - acc: 0.4173 - val_loss: 0.1026 - val_acc: 0.4237\n",
      "Epoch 128/1000\n",
      "0s - loss: 0.1033 - acc: 0.4181 - val_loss: 0.1026 - val_acc: 0.4245\n",
      "Epoch 129/1000\n",
      "0s - loss: 0.1034 - acc: 0.4183 - val_loss: 0.1026 - val_acc: 0.4247\n",
      "Epoch 130/1000\n",
      "0s - loss: 0.1033 - acc: 0.4188 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 131/1000\n",
      "0s - loss: 0.1034 - acc: 0.4185 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 132/1000\n",
      "0s - loss: 0.1034 - acc: 0.4187 - val_loss: 0.1027 - val_acc: 0.4246\n",
      "Epoch 133/1000\n",
      "0s - loss: 0.1034 - acc: 0.4179 - val_loss: 0.1026 - val_acc: 0.4242\n",
      "Epoch 134/1000\n",
      "0s - loss: 0.1034 - acc: 0.4183 - val_loss: 0.1028 - val_acc: 0.4247\n",
      "Epoch 135/1000\n",
      "0s - loss: 0.1033 - acc: 0.4199 - val_loss: 0.1028 - val_acc: 0.4233\n",
      "Epoch 136/1000\n",
      "0s - loss: 0.1033 - acc: 0.4174 - val_loss: 0.1026 - val_acc: 0.4230\n",
      "Epoch 137/1000\n",
      "0s - loss: 0.1033 - acc: 0.4184 - val_loss: 0.1026 - val_acc: 0.4251\n",
      "Epoch 138/1000\n",
      "0s - loss: 0.1034 - acc: 0.4183 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 139/1000\n",
      "0s - loss: 0.1033 - acc: 0.4187 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 140/1000\n",
      "0s - loss: 0.1033 - acc: 0.4184 - val_loss: 0.1025 - val_acc: 0.4244\n",
      "Epoch 141/1000\n",
      "0s - loss: 0.1033 - acc: 0.4180 - val_loss: 0.1026 - val_acc: 0.4241\n",
      "Epoch 142/1000\n",
      "0s - loss: 0.1033 - acc: 0.4182 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 143/1000\n",
      "0s - loss: 0.1034 - acc: 0.4188 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 144/1000\n",
      "0s - loss: 0.1034 - acc: 0.4182 - val_loss: 0.1027 - val_acc: 0.4244\n",
      "Epoch 145/1000\n",
      "0s - loss: 0.1033 - acc: 0.4199 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 146/1000\n",
      "0s - loss: 0.1033 - acc: 0.4195 - val_loss: 0.1027 - val_acc: 0.4243\n",
      "Epoch 147/1000\n",
      "0s - loss: 0.1033 - acc: 0.4177 - val_loss: 0.1026 - val_acc: 0.4246\n",
      "Epoch 148/1000\n",
      "0s - loss: 0.1033 - acc: 0.4175 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 149/1000\n",
      "0s - loss: 0.1033 - acc: 0.4176 - val_loss: 0.1026 - val_acc: 0.4247\n",
      "Epoch 150/1000\n",
      "0s - loss: 0.1033 - acc: 0.4186 - val_loss: 0.1025 - val_acc: 0.4240\n",
      "Epoch 151/1000\n",
      "0s - loss: 0.1033 - acc: 0.4200 - val_loss: 0.1026 - val_acc: 0.4244\n",
      "Epoch 152/1000\n",
      "0s - loss: 0.1033 - acc: 0.4192 - val_loss: 0.1026 - val_acc: 0.4242\n",
      "Epoch 153/1000\n",
      "0s - loss: 0.1033 - acc: 0.4193 - val_loss: 0.1026 - val_acc: 0.4249\n",
      "Epoch 154/1000\n",
      "0s - loss: 0.1033 - acc: 0.4194 - val_loss: 0.1027 - val_acc: 0.4241\n",
      "Epoch 155/1000\n",
      "0s - loss: 0.1033 - acc: 0.4185 - val_loss: 0.1026 - val_acc: 0.4248\n",
      "Epoch 156/1000\n",
      "0s - loss: 0.1033 - acc: 0.4182 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 157/1000\n",
      "0s - loss: 0.1033 - acc: 0.4204 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 158/1000\n",
      "0s - loss: 0.1033 - acc: 0.4187 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 159/1000\n",
      "0s - loss: 0.1033 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4240\n",
      "Epoch 160/1000\n",
      "0s - loss: 0.1033 - acc: 0.4195 - val_loss: 0.1027 - val_acc: 0.4246\n",
      "Epoch 161/1000\n",
      "0s - loss: 0.1034 - acc: 0.4181 - val_loss: 0.1027 - val_acc: 0.4245\n",
      "Epoch 162/1000\n",
      "0s - loss: 0.1033 - acc: 0.4182 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 163/1000\n",
      "0s - loss: 0.1033 - acc: 0.4183 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 164/1000\n",
      "0s - loss: 0.1033 - acc: 0.4188 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 165/1000\n",
      "0s - loss: 0.1033 - acc: 0.4189 - val_loss: 0.1025 - val_acc: 0.4244\n",
      "Epoch 166/1000\n",
      "0s - loss: 0.1033 - acc: 0.4185 - val_loss: 0.1025 - val_acc: 0.4241\n",
      "Epoch 167/1000\n",
      "0s - loss: 0.1033 - acc: 0.4190 - val_loss: 0.1026 - val_acc: 0.4241\n",
      "Epoch 168/1000\n",
      "0s - loss: 0.1033 - acc: 0.4180 - val_loss: 0.1026 - val_acc: 0.4243\n",
      "Epoch 169/1000\n",
      "0s - loss: 0.1033 - acc: 0.4186 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 170/1000\n",
      "0s - loss: 0.1033 - acc: 0.4191 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 171/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 172/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 173/1000\n",
      "0s - loss: 0.1033 - acc: 0.4199 - val_loss: 0.1027 - val_acc: 0.4247\n",
      "Epoch 174/1000\n",
      "0s - loss: 0.1033 - acc: 0.4187 - val_loss: 0.1026 - val_acc: 0.4247\n",
      "Epoch 175/1000\n",
      "0s - loss: 0.1033 - acc: 0.4198 - val_loss: 0.1028 - val_acc: 0.4235\n",
      "Epoch 176/1000\n",
      "0s - loss: 0.1033 - acc: 0.4189 - val_loss: 0.1025 - val_acc: 0.4249\n",
      "Epoch 177/1000\n",
      "0s - loss: 0.1033 - acc: 0.4176 - val_loss: 0.1025 - val_acc: 0.4246\n",
      "Epoch 178/1000\n",
      "0s - loss: 0.1032 - acc: 0.4192 - val_loss: 0.1027 - val_acc: 0.4243\n",
      "Epoch 179/1000\n",
      "0s - loss: 0.1033 - acc: 0.4200 - val_loss: 0.1026 - val_acc: 0.4235\n",
      "Epoch 180/1000\n",
      "0s - loss: 0.1033 - acc: 0.4199 - val_loss: 0.1025 - val_acc: 0.4246\n",
      "Epoch 181/1000\n",
      "0s - loss: 0.1033 - acc: 0.4194 - val_loss: 0.1026 - val_acc: 0.4235\n",
      "Epoch 182/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1026 - val_acc: 0.4233\n",
      "Epoch 183/1000\n",
      "0s - loss: 0.1033 - acc: 0.4183 - val_loss: 0.1026 - val_acc: 0.4245\n",
      "Epoch 184/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1026 - val_acc: 0.4238\n",
      "Epoch 185/1000\n",
      "0s - loss: 0.1033 - acc: 0.4196 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 186/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1026 - val_acc: 0.4239\n",
      "Epoch 187/1000\n",
      "0s - loss: 0.1032 - acc: 0.4195 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 188/1000\n",
      "0s - loss: 0.1032 - acc: 0.4186 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 189/1000\n",
      "0s - loss: 0.1033 - acc: 0.4183 - val_loss: 0.1026 - val_acc: 0.4240\n",
      "Epoch 190/1000\n",
      "0s - loss: 0.1032 - acc: 0.4193 - val_loss: 0.1026 - val_acc: 0.4241\n",
      "Epoch 191/1000\n",
      "0s - loss: 0.1033 - acc: 0.4192 - val_loss: 0.1027 - val_acc: 0.4248\n",
      "Epoch 192/1000\n",
      "0s - loss: 0.1033 - acc: 0.4186 - val_loss: 0.1026 - val_acc: 0.4257\n",
      "Epoch 193/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 194/1000\n",
      "0s - loss: 0.1033 - acc: 0.4188 - val_loss: 0.1026 - val_acc: 0.4230\n",
      "Epoch 195/1000\n",
      "0s - loss: 0.1033 - acc: 0.4196 - val_loss: 0.1026 - val_acc: 0.4249\n",
      "Epoch 196/1000\n",
      "0s - loss: 0.1033 - acc: 0.4182 - val_loss: 0.1026 - val_acc: 0.4245\n",
      "Epoch 197/1000\n",
      "0s - loss: 0.1033 - acc: 0.4191 - val_loss: 0.1026 - val_acc: 0.4249\n",
      "Epoch 198/1000\n",
      "0s - loss: 0.1032 - acc: 0.4211 - val_loss: 0.1026 - val_acc: 0.4246\n",
      "Epoch 199/1000\n",
      "0s - loss: 0.1033 - acc: 0.4186 - val_loss: 0.1026 - val_acc: 0.4255\n",
      "Epoch 200/1000\n",
      "0s - loss: 0.1033 - acc: 0.4192 - val_loss: 0.1025 - val_acc: 0.4256\n",
      "Epoch 201/1000\n",
      "0s - loss: 0.1032 - acc: 0.4184 - val_loss: 0.1027 - val_acc: 0.4253\n",
      "Epoch 202/1000\n",
      "0s - loss: 0.1033 - acc: 0.4188 - val_loss: 0.1026 - val_acc: 0.4243\n",
      "Epoch 203/1000\n",
      "0s - loss: 0.1032 - acc: 0.4190 - val_loss: 0.1028 - val_acc: 0.4240\n",
      "Epoch 204/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1026 - val_acc: 0.4222\n",
      "Epoch 205/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1027 - val_acc: 0.4242\n",
      "Epoch 206/1000\n",
      "0s - loss: 0.1032 - acc: 0.4199 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 207/1000\n",
      "0s - loss: 0.1032 - acc: 0.4196 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 208/1000\n",
      "0s - loss: 0.1032 - acc: 0.4204 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 209/1000\n",
      "0s - loss: 0.1033 - acc: 0.4194 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 210/1000\n",
      "0s - loss: 0.1032 - acc: 0.4185 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 211/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 212/1000\n",
      "0s - loss: 0.1033 - acc: 0.4204 - val_loss: 0.1025 - val_acc: 0.4249\n",
      "Epoch 213/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 214/1000\n",
      "0s - loss: 0.1032 - acc: 0.4193 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 215/1000\n",
      "0s - loss: 0.1032 - acc: 0.4189 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 216/1000\n",
      "0s - loss: 0.1032 - acc: 0.4190 - val_loss: 0.1026 - val_acc: 0.4247\n",
      "Epoch 217/1000\n",
      "0s - loss: 0.1033 - acc: 0.4191 - val_loss: 0.1027 - val_acc: 0.4245\n",
      "Epoch 218/1000\n",
      "0s - loss: 0.1032 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 219/1000\n",
      "0s - loss: 0.1032 - acc: 0.4204 - val_loss: 0.1027 - val_acc: 0.4250\n",
      "Epoch 220/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1026 - val_acc: 0.4237\n",
      "Epoch 221/1000\n",
      "0s - loss: 0.1032 - acc: 0.4199 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 222/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 223/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 224/1000\n",
      "0s - loss: 0.1032 - acc: 0.4187 - val_loss: 0.1026 - val_acc: 0.4255\n",
      "Epoch 225/1000\n",
      "0s - loss: 0.1032 - acc: 0.4185 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 226/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 227/1000\n",
      "0s - loss: 0.1032 - acc: 0.4204 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 228/1000\n",
      "0s - loss: 0.1032 - acc: 0.4200 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 229/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1026 - val_acc: 0.4256\n",
      "Epoch 230/1000\n",
      "0s - loss: 0.1032 - acc: 0.4201 - val_loss: 0.1027 - val_acc: 0.4248\n",
      "Epoch 231/1000\n",
      "0s - loss: 0.1032 - acc: 0.4216 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 232/1000\n",
      "0s - loss: 0.1033 - acc: 0.4197 - val_loss: 0.1026 - val_acc: 0.4255\n",
      "Epoch 233/1000\n",
      "0s - loss: 0.1032 - acc: 0.4188 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 234/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 235/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1026 - val_acc: 0.4256\n",
      "Epoch 236/1000\n",
      "0s - loss: 0.1032 - acc: 0.4190 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 237/1000\n",
      "0s - loss: 0.1032 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 238/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 239/1000\n",
      "0s - loss: 0.1032 - acc: 0.4201 - val_loss: 0.1027 - val_acc: 0.4245\n",
      "Epoch 240/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 241/1000\n",
      "0s - loss: 0.1032 - acc: 0.4193 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 242/1000\n",
      "0s - loss: 0.1032 - acc: 0.4201 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 243/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 244/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1026 - val_acc: 0.4246\n",
      "Epoch 245/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1024 - val_acc: 0.4252\n",
      "Epoch 246/1000\n",
      "0s - loss: 0.1032 - acc: 0.4193 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 247/1000\n",
      "0s - loss: 0.1032 - acc: 0.4210 - val_loss: 0.1026 - val_acc: 0.4250\n",
      "Epoch 248/1000\n",
      "0s - loss: 0.1032 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 249/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 250/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 251/1000\n",
      "0s - loss: 0.1033 - acc: 0.4189 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 252/1000\n",
      "0s - loss: 0.1032 - acc: 0.4200 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 253/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 254/1000\n",
      "0s - loss: 0.1032 - acc: 0.4200 - val_loss: 0.1026 - val_acc: 0.4242\n",
      "Epoch 255/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 256/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 257/1000\n",
      "0s - loss: 0.1031 - acc: 0.4199 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 258/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 259/1000\n",
      "0s - loss: 0.1032 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4247\n",
      "Epoch 260/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 261/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 262/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 263/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 264/1000\n",
      "0s - loss: 0.1032 - acc: 0.4200 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 265/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 266/1000\n",
      "0s - loss: 0.1032 - acc: 0.4199 - val_loss: 0.1025 - val_acc: 0.4234\n",
      "Epoch 267/1000\n",
      "0s - loss: 0.1032 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 268/1000\n",
      "0s - loss: 0.1032 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 269/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1026 - val_acc: 0.4247\n",
      "Epoch 270/1000\n",
      "0s - loss: 0.1032 - acc: 0.4201 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 271/1000\n",
      "0s - loss: 0.1032 - acc: 0.4196 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 272/1000\n",
      "0s - loss: 0.1032 - acc: 0.4195 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 273/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1025 - val_acc: 0.4246\n",
      "Epoch 274/1000\n",
      "0s - loss: 0.1032 - acc: 0.4188 - val_loss: 0.1025 - val_acc: 0.4239\n",
      "Epoch 275/1000\n",
      "0s - loss: 0.1032 - acc: 0.4192 - val_loss: 0.1025 - val_acc: 0.4233\n",
      "Epoch 276/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1026 - val_acc: 0.4235\n",
      "Epoch 277/1000\n",
      "0s - loss: 0.1032 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 278/1000\n",
      "0s - loss: 0.1032 - acc: 0.4191 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 279/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4234\n",
      "Epoch 280/1000\n",
      "0s - loss: 0.1032 - acc: 0.4190 - val_loss: 0.1025 - val_acc: 0.4234\n",
      "Epoch 281/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1024 - val_acc: 0.4251\n",
      "Epoch 282/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 283/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1026 - val_acc: 0.4246\n",
      "Epoch 284/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4250\n",
      "Epoch 285/1000\n",
      "0s - loss: 0.1032 - acc: 0.4201 - val_loss: 0.1025 - val_acc: 0.4223\n",
      "Epoch 286/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 287/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4249\n",
      "Epoch 288/1000\n",
      "0s - loss: 0.1032 - acc: 0.4214 - val_loss: 0.1026 - val_acc: 0.4242\n",
      "Epoch 289/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4246\n",
      "Epoch 290/1000\n",
      "0s - loss: 0.1032 - acc: 0.4199 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 291/1000\n",
      "0s - loss: 0.1032 - acc: 0.4193 - val_loss: 0.1025 - val_acc: 0.4249\n",
      "Epoch 292/1000\n",
      "0s - loss: 0.1031 - acc: 0.4183 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 293/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1025 - val_acc: 0.4246\n",
      "Epoch 294/1000\n",
      "0s - loss: 0.1031 - acc: 0.4199 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 295/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 296/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 297/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 298/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 299/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1026 - val_acc: 0.4231\n",
      "Epoch 300/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 301/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 302/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 303/1000\n",
      "0s - loss: 0.1032 - acc: 0.4195 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 304/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 305/1000\n",
      "0s - loss: 0.1032 - acc: 0.4195 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 306/1000\n",
      "0s - loss: 0.1031 - acc: 0.4189 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 307/1000\n",
      "0s - loss: 0.1032 - acc: 0.4204 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 308/1000\n",
      "0s - loss: 0.1031 - acc: 0.4204 - val_loss: 0.1025 - val_acc: 0.4222\n",
      "Epoch 309/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 310/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1026 - val_acc: 0.4258\n",
      "Epoch 311/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1025 - val_acc: 0.4265\n",
      "Epoch 312/1000\n",
      "0s - loss: 0.1032 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 313/1000\n",
      "0s - loss: 0.1032 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4239\n",
      "Epoch 314/1000\n",
      "0s - loss: 0.1032 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 315/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 316/1000\n",
      "0s - loss: 0.1031 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 317/1000\n",
      "0s - loss: 0.1032 - acc: 0.4201 - val_loss: 0.1025 - val_acc: 0.4264\n",
      "Epoch 318/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 319/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1026 - val_acc: 0.4252\n",
      "Epoch 320/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1026 - val_acc: 0.4239\n",
      "Epoch 321/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 322/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 323/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 324/1000\n",
      "0s - loss: 0.1032 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 325/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 326/1000\n",
      "0s - loss: 0.1032 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 327/1000\n",
      "0s - loss: 0.1032 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 328/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1027 - val_acc: 0.4251\n",
      "Epoch 329/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1024 - val_acc: 0.4243\n",
      "Epoch 330/1000\n",
      "0s - loss: 0.1032 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4246\n",
      "Epoch 331/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 332/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 333/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4256\n",
      "Epoch 334/1000\n",
      "0s - loss: 0.1032 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 335/1000\n",
      "0s - loss: 0.1032 - acc: 0.4199 - val_loss: 0.1025 - val_acc: 0.4237\n",
      "Epoch 336/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1026 - val_acc: 0.4255\n",
      "Epoch 337/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 338/1000\n",
      "0s - loss: 0.1032 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 339/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 340/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 341/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 342/1000\n",
      "0s - loss: 0.1031 - acc: 0.4201 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 343/1000\n",
      "0s - loss: 0.1032 - acc: 0.4210 - val_loss: 0.1026 - val_acc: 0.4243\n",
      "Epoch 344/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 345/1000\n",
      "0s - loss: 0.1031 - acc: 0.4196 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 346/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 347/1000\n",
      "0s - loss: 0.1032 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 348/1000\n",
      "1s - loss: 0.1032 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 349/1000\n",
      "0s - loss: 0.1032 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 350/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 351/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 352/1000\n",
      "0s - loss: 0.1032 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 353/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 354/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 355/1000\n",
      "0s - loss: 0.1032 - acc: 0.4213 - val_loss: 0.1026 - val_acc: 0.4259\n",
      "Epoch 356/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4251\n",
      "Epoch 357/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4243\n",
      "Epoch 358/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 359/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 360/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 361/1000\n",
      "0s - loss: 0.1032 - acc: 0.4199 - val_loss: 0.1024 - val_acc: 0.4250\n",
      "Epoch 362/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 363/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 364/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 365/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 366/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 367/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1027 - val_acc: 0.4252\n",
      "Epoch 368/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 369/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 370/1000\n",
      "0s - loss: 0.1032 - acc: 0.4192 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 371/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1026 - val_acc: 0.4229\n",
      "Epoch 372/1000\n",
      "0s - loss: 0.1031 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4256\n",
      "Epoch 373/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 374/1000\n",
      "0s - loss: 0.1032 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4246\n",
      "Epoch 375/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 376/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 377/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4264\n",
      "Epoch 378/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 379/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 380/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 381/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 382/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4244\n",
      "Epoch 383/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 384/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4262\n",
      "Epoch 385/1000\n",
      "0s - loss: 0.1031 - acc: 0.4224 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 386/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 387/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4265\n",
      "Epoch 388/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 389/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4250\n",
      "Epoch 390/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1023 - val_acc: 0.4265\n",
      "Epoch 391/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 392/1000\n",
      "0s - loss: 0.1031 - acc: 0.4227 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 393/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4252\n",
      "Epoch 394/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 395/1000\n",
      "0s - loss: 0.1031 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 396/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1026 - val_acc: 0.4255\n",
      "Epoch 397/1000\n",
      "0s - loss: 0.1032 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 398/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4271\n",
      "Epoch 399/1000\n",
      "0s - loss: 0.1032 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4241\n",
      "Epoch 400/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 401/1000\n",
      "0s - loss: 0.1032 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 402/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1026 - val_acc: 0.4260\n",
      "Epoch 403/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 404/1000\n",
      "0s - loss: 0.1031 - acc: 0.4203 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 405/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 406/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 407/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 408/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4236\n",
      "Epoch 409/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 410/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4239\n",
      "Epoch 411/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4272\n",
      "Epoch 412/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4224\n",
      "Epoch 413/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4247\n",
      "Epoch 414/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 415/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1026 - val_acc: 0.4231\n",
      "Epoch 416/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 417/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 418/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1026 - val_acc: 0.4266\n",
      "Epoch 419/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 420/1000\n",
      "0s - loss: 0.1032 - acc: 0.4191 - val_loss: 0.1024 - val_acc: 0.4247\n",
      "Epoch 421/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 422/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 423/1000\n",
      "0s - loss: 0.1031 - acc: 0.4201 - val_loss: 0.1024 - val_acc: 0.4251\n",
      "Epoch 424/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 425/1000\n",
      "0s - loss: 0.1031 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 426/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 427/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 428/1000\n",
      "0s - loss: 0.1031 - acc: 0.4201 - val_loss: 0.1023 - val_acc: 0.4268\n",
      "Epoch 429/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 430/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 431/1000\n",
      "0s - loss: 0.1031 - acc: 0.4196 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 432/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 433/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4262\n",
      "Epoch 434/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 435/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1025 - val_acc: 0.4264\n",
      "Epoch 436/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 437/1000\n",
      "0s - loss: 0.1031 - acc: 0.4199 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 438/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 439/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 440/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 441/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1025 - val_acc: 0.4245\n",
      "Epoch 442/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 443/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 444/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4264\n",
      "Epoch 445/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 446/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4262\n",
      "Epoch 447/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 448/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 449/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 450/1000\n",
      "0s - loss: 0.1031 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 451/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 452/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 453/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 454/1000\n",
      "0s - loss: 0.1030 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 455/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 456/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 457/1000\n",
      "0s - loss: 0.1031 - acc: 0.4200 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 458/1000\n",
      "0s - loss: 0.1031 - acc: 0.4201 - val_loss: 0.1025 - val_acc: 0.4262\n",
      "Epoch 459/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 460/1000\n",
      "0s - loss: 0.1031 - acc: 0.4203 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 461/1000\n",
      "0s - loss: 0.1031 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 462/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 463/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4224\n",
      "Epoch 464/1000\n",
      "0s - loss: 0.1030 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4243\n",
      "Epoch 465/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 466/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 467/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 468/1000\n",
      "0s - loss: 0.1031 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 469/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4245\n",
      "Epoch 470/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 471/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 472/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 473/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 474/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 475/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 476/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 477/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1023 - val_acc: 0.4261\n",
      "Epoch 478/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 479/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 480/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1023 - val_acc: 0.4260\n",
      "Epoch 481/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 482/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1023 - val_acc: 0.4261\n",
      "Epoch 483/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 484/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 485/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1023 - val_acc: 0.4246\n",
      "Epoch 486/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 487/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 488/1000\n",
      "0s - loss: 0.1031 - acc: 0.4203 - val_loss: 0.1025 - val_acc: 0.4244\n",
      "Epoch 489/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 490/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 491/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 492/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 493/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 494/1000\n",
      "0s - loss: 0.1031 - acc: 0.4201 - val_loss: 0.1025 - val_acc: 0.4245\n",
      "Epoch 495/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 496/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4251\n",
      "Epoch 497/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 498/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 499/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 500/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1026 - val_acc: 0.4260\n",
      "Epoch 501/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 502/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 503/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4235\n",
      "Epoch 504/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 505/1000\n",
      "0s - loss: 0.1031 - acc: 0.4201 - val_loss: 0.1024 - val_acc: 0.4246\n",
      "Epoch 506/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 507/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 508/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 509/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4256\n",
      "Epoch 510/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4236\n",
      "Epoch 511/1000\n",
      "0s - loss: 0.1032 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 512/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4238\n",
      "Epoch 513/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4239\n",
      "Epoch 514/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 515/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4238\n",
      "Epoch 516/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 517/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 518/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 519/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4237\n",
      "Epoch 520/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 521/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1025 - val_acc: 0.4249\n",
      "Epoch 522/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 523/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1023 - val_acc: 0.4262\n",
      "Epoch 524/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4273\n",
      "Epoch 525/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 526/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 527/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4241\n",
      "Epoch 528/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 529/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 530/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 531/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 532/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 533/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 534/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 535/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4253\n",
      "Epoch 536/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 537/1000\n",
      "0s - loss: 0.1031 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 538/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1025 - val_acc: 0.4274\n",
      "Epoch 539/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1023 - val_acc: 0.4265\n",
      "Epoch 540/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1023 - val_acc: 0.4275\n",
      "Epoch 541/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 542/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 543/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 544/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 545/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 546/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 547/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 548/1000\n",
      "0s - loss: 0.1031 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4247\n",
      "Epoch 549/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 550/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 551/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1023 - val_acc: 0.4258\n",
      "Epoch 552/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 553/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1025 - val_acc: 0.4268\n",
      "Epoch 554/1000\n",
      "0s - loss: 0.1031 - acc: 0.4224 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 555/1000\n",
      "0s - loss: 0.1031 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 556/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 557/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 558/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 559/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1023 - val_acc: 0.4260\n",
      "Epoch 560/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 561/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4252\n",
      "Epoch 562/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4238\n",
      "Epoch 563/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4245\n",
      "Epoch 564/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4224\n",
      "Epoch 565/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1023 - val_acc: 0.4264\n",
      "Epoch 566/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4239\n",
      "Epoch 567/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4260\n",
      "Epoch 568/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 569/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 570/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 571/1000\n",
      "0s - loss: 0.1031 - acc: 0.4199 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 572/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 573/1000\n",
      "0s - loss: 0.1031 - acc: 0.4196 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 574/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 575/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1023 - val_acc: 0.4271\n",
      "Epoch 576/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1023 - val_acc: 0.4277\n",
      "Epoch 577/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 578/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 579/1000\n",
      "0s - loss: 0.1031 - acc: 0.4226 - val_loss: 0.1025 - val_acc: 0.4265\n",
      "Epoch 580/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1023 - val_acc: 0.4244\n",
      "Epoch 581/1000\n",
      "0s - loss: 0.1031 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 582/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 583/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 584/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4280\n",
      "Epoch 585/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 586/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4242\n",
      "Epoch 587/1000\n",
      "0s - loss: 0.1030 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 588/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 589/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 590/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4251\n",
      "Epoch 591/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 592/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 593/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4249\n",
      "Epoch 594/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4244\n",
      "Epoch 595/1000\n",
      "0s - loss: 0.1031 - acc: 0.4226 - val_loss: 0.1025 - val_acc: 0.4255\n",
      "Epoch 596/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 597/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4270\n",
      "Epoch 598/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 599/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1023 - val_acc: 0.4262\n",
      "Epoch 600/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 601/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1023 - val_acc: 0.4267\n",
      "Epoch 602/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 603/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 604/1000\n",
      "0s - loss: 0.1030 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 605/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 606/1000\n",
      "0s - loss: 0.1030 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 607/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 608/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 609/1000\n",
      "0s - loss: 0.1030 - acc: 0.4207 - val_loss: 0.1023 - val_acc: 0.4255\n",
      "Epoch 610/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4280\n",
      "Epoch 611/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4249\n",
      "Epoch 612/1000\n",
      "0s - loss: 0.1031 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 613/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 614/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 615/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4252\n",
      "Epoch 616/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1023 - val_acc: 0.4261\n",
      "Epoch 617/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1023 - val_acc: 0.4259\n",
      "Epoch 618/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4252\n",
      "Epoch 619/1000\n",
      "0s - loss: 0.1030 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4273\n",
      "Epoch 620/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4249\n",
      "Epoch 621/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 622/1000\n",
      "0s - loss: 0.1031 - acc: 0.4200 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 623/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 624/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 625/1000\n",
      "0s - loss: 0.1031 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 626/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 627/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4262\n",
      "Epoch 628/1000\n",
      "0s - loss: 0.1031 - acc: 0.4199 - val_loss: 0.1025 - val_acc: 0.4254\n",
      "Epoch 629/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1023 - val_acc: 0.4272\n",
      "Epoch 630/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4249\n",
      "Epoch 631/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 632/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 633/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 634/1000\n",
      "0s - loss: 0.1030 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 635/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1023 - val_acc: 0.4271\n",
      "Epoch 636/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 637/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 638/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4245\n",
      "Epoch 639/1000\n",
      "0s - loss: 0.1031 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 640/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4251\n",
      "Epoch 641/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 642/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 643/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1025 - val_acc: 0.4262\n",
      "Epoch 644/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 645/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 646/1000\n",
      "0s - loss: 0.1031 - acc: 0.4197 - val_loss: 0.1025 - val_acc: 0.4269\n",
      "Epoch 647/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 648/1000\n",
      "0s - loss: 0.1031 - acc: 0.4200 - val_loss: 0.1024 - val_acc: 0.4245\n",
      "Epoch 649/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 650/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4262\n",
      "Epoch 651/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 652/1000\n",
      "0s - loss: 0.1030 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 653/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 654/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 655/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4270\n",
      "Epoch 656/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 657/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 658/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4246\n",
      "Epoch 659/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 660/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4237\n",
      "Epoch 661/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 662/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4281\n",
      "Epoch 663/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 664/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 665/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 666/1000\n",
      "0s - loss: 0.1031 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 667/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1023 - val_acc: 0.4267\n",
      "Epoch 668/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1023 - val_acc: 0.4264\n",
      "Epoch 669/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1025 - val_acc: 0.4272\n",
      "Epoch 670/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 671/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 672/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 673/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4274\n",
      "Epoch 674/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 675/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1023 - val_acc: 0.4260\n",
      "Epoch 676/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1023 - val_acc: 0.4269\n",
      "Epoch 677/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 678/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4263\n",
      "Epoch 679/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 680/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1023 - val_acc: 0.4271\n",
      "Epoch 681/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 682/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 683/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1025 - val_acc: 0.4242\n",
      "Epoch 684/1000\n",
      "0s - loss: 0.1031 - acc: 0.4220 - val_loss: 0.1026 - val_acc: 0.4268\n",
      "Epoch 685/1000\n",
      "0s - loss: 0.1030 - acc: 0.4236 - val_loss: 0.1024 - val_acc: 0.4245\n",
      "Epoch 686/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4250\n",
      "Epoch 687/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 688/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 689/1000\n",
      "0s - loss: 0.1031 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 690/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 691/1000\n",
      "0s - loss: 0.1031 - acc: 0.4198 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 692/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 693/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 694/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4267\n",
      "Epoch 695/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 696/1000\n",
      "0s - loss: 0.1031 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 697/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 698/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 699/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1026 - val_acc: 0.4271\n",
      "Epoch 700/1000\n",
      "0s - loss: 0.1031 - acc: 0.4206 - val_loss: 0.1023 - val_acc: 0.4268\n",
      "Epoch 701/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 702/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4279\n",
      "Epoch 703/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 704/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1025 - val_acc: 0.4251\n",
      "Epoch 705/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 706/1000\n",
      "0s - loss: 0.1031 - acc: 0.4211 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 707/1000\n",
      "0s - loss: 0.1031 - acc: 0.4204 - val_loss: 0.1023 - val_acc: 0.4254\n",
      "Epoch 708/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1023 - val_acc: 0.4259\n",
      "Epoch 709/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4235\n",
      "Epoch 710/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 711/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4250\n",
      "Epoch 712/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 713/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 714/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1023 - val_acc: 0.4257\n",
      "Epoch 715/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1025 - val_acc: 0.4248\n",
      "Epoch 716/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1025 - val_acc: 0.4256\n",
      "Epoch 717/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 718/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4271\n",
      "Epoch 719/1000\n",
      "0s - loss: 0.1030 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 720/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 721/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 722/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 723/1000\n",
      "0s - loss: 0.1031 - acc: 0.4212 - val_loss: 0.1027 - val_acc: 0.4251\n",
      "Epoch 724/1000\n",
      "0s - loss: 0.1030 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 725/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1025 - val_acc: 0.4258\n",
      "Epoch 726/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1023 - val_acc: 0.4256\n",
      "Epoch 727/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 728/1000\n",
      "0s - loss: 0.1031 - acc: 0.4235 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 729/1000\n",
      "0s - loss: 0.1030 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 730/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4249\n",
      "Epoch 731/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 732/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4274\n",
      "Epoch 733/1000\n",
      "0s - loss: 0.1031 - acc: 0.4230 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 734/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 735/1000\n",
      "0s - loss: 0.1030 - acc: 0.4202 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 736/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 737/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 738/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 739/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4224\n",
      "Epoch 740/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1023 - val_acc: 0.4263\n",
      "Epoch 741/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 742/1000\n",
      "0s - loss: 0.1030 - acc: 0.4234 - val_loss: 0.1025 - val_acc: 0.4269\n",
      "Epoch 743/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 744/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 745/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4233\n",
      "Epoch 746/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 747/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1025 - val_acc: 0.4256\n",
      "Epoch 748/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 749/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 750/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4275\n",
      "Epoch 751/1000\n",
      "0s - loss: 0.1031 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 752/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 753/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 754/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 755/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 756/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 757/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 758/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 759/1000\n",
      "0s - loss: 0.1030 - acc: 0.4233 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 760/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4247\n",
      "Epoch 761/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 762/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1025 - val_acc: 0.4268\n",
      "Epoch 763/1000\n",
      "0s - loss: 0.1030 - acc: 0.4239 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 764/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1023 - val_acc: 0.4262\n",
      "Epoch 765/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 766/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4248\n",
      "Epoch 767/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1025 - val_acc: 0.4272\n",
      "Epoch 768/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 769/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4247\n",
      "Epoch 770/1000\n",
      "0s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4234\n",
      "Epoch 771/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4231\n",
      "Epoch 772/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1023 - val_acc: 0.4271\n",
      "Epoch 773/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 774/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 775/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1023 - val_acc: 0.4268\n",
      "Epoch 776/1000\n",
      "0s - loss: 0.1031 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 777/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1023 - val_acc: 0.4273\n",
      "Epoch 778/1000\n",
      "0s - loss: 0.1031 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 779/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 780/1000\n",
      "0s - loss: 0.1030 - acc: 0.4237 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 781/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1023 - val_acc: 0.4285\n",
      "Epoch 782/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4273\n",
      "Epoch 783/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1025 - val_acc: 0.4273\n",
      "Epoch 784/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 785/1000\n",
      "0s - loss: 0.1030 - acc: 0.4202 - val_loss: 0.1023 - val_acc: 0.4267\n",
      "Epoch 786/1000\n",
      "1s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4252\n",
      "Epoch 787/1000\n",
      "1s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 788/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 789/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 790/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4246\n",
      "Epoch 791/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 792/1000\n",
      "1s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 793/1000\n",
      "1s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 794/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 795/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 796/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 797/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4256\n",
      "Epoch 798/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1025 - val_acc: 0.4250\n",
      "Epoch 799/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1023 - val_acc: 0.4256\n",
      "Epoch 800/1000\n",
      "0s - loss: 0.1030 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 801/1000\n",
      "0s - loss: 0.1030 - acc: 0.4206 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 802/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1023 - val_acc: 0.4263\n",
      "Epoch 803/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 804/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 805/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 806/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4279\n",
      "Epoch 807/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 808/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1025 - val_acc: 0.4276\n",
      "Epoch 809/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4274\n",
      "Epoch 810/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1025 - val_acc: 0.4272\n",
      "Epoch 811/1000\n",
      "0s - loss: 0.1031 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 812/1000\n",
      "0s - loss: 0.1031 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 813/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 814/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 815/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1025 - val_acc: 0.4266\n",
      "Epoch 816/1000\n",
      "1s - loss: 0.1030 - acc: 0.4213 - val_loss: 0.1025 - val_acc: 0.4265\n",
      "Epoch 817/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 818/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4246\n",
      "Epoch 819/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1023 - val_acc: 0.4269\n",
      "Epoch 820/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1025 - val_acc: 0.4278\n",
      "Epoch 821/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1025 - val_acc: 0.4265\n",
      "Epoch 822/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4249\n",
      "Epoch 823/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4257\n",
      "Epoch 824/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 825/1000\n",
      "0s - loss: 0.1030 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4279\n",
      "Epoch 826/1000\n",
      "0s - loss: 0.1031 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 827/1000\n",
      "0s - loss: 0.1030 - acc: 0.4203 - val_loss: 0.1023 - val_acc: 0.4269\n",
      "Epoch 828/1000\n",
      "0s - loss: 0.1031 - acc: 0.4224 - val_loss: 0.1023 - val_acc: 0.4263\n",
      "Epoch 829/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1023 - val_acc: 0.4275\n",
      "Epoch 830/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1025 - val_acc: 0.4261\n",
      "Epoch 831/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 832/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 833/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 834/1000\n",
      "0s - loss: 0.1030 - acc: 0.4205 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 835/1000\n",
      "0s - loss: 0.1030 - acc: 0.4208 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 836/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 837/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 838/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1023 - val_acc: 0.4266\n",
      "Epoch 839/1000\n",
      "0s - loss: 0.1031 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 840/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1025 - val_acc: 0.4264\n",
      "Epoch 841/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4258\n",
      "Epoch 842/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 843/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1023 - val_acc: 0.4279\n",
      "Epoch 844/1000\n",
      "0s - loss: 0.1031 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 845/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1025 - val_acc: 0.4265\n",
      "Epoch 846/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 847/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1023 - val_acc: 0.4275\n",
      "Epoch 848/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 849/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4279\n",
      "Epoch 850/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 851/1000\n",
      "0s - loss: 0.1030 - acc: 0.4239 - val_loss: 0.1023 - val_acc: 0.4275\n",
      "Epoch 852/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 853/1000\n",
      "0s - loss: 0.1030 - acc: 0.4236 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 854/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 855/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 856/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 857/1000\n",
      "0s - loss: 0.1030 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 858/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1023 - val_acc: 0.4278\n",
      "Epoch 859/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 860/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 861/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4229\n",
      "Epoch 862/1000\n",
      "0s - loss: 0.1030 - acc: 0.4234 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 863/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1025 - val_acc: 0.4239\n",
      "Epoch 864/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 865/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4279\n",
      "Epoch 866/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 867/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 868/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1024 - val_acc: 0.4231\n",
      "Epoch 869/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 870/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 871/1000\n",
      "1s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 872/1000\n",
      "1s - loss: 0.1031 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4282\n",
      "Epoch 873/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 874/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 875/1000\n",
      "0s - loss: 0.1030 - acc: 0.4232 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 876/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 877/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4237\n",
      "Epoch 878/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4273\n",
      "Epoch 879/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1023 - val_acc: 0.4278\n",
      "Epoch 880/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4273\n",
      "Epoch 881/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 882/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4282\n",
      "Epoch 883/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4279\n",
      "Epoch 884/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1025 - val_acc: 0.4273\n",
      "Epoch 885/1000\n",
      "0s - loss: 0.1031 - acc: 0.4208 - val_loss: 0.1025 - val_acc: 0.4276\n",
      "Epoch 886/1000\n",
      "1s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1023 - val_acc: 0.4266\n",
      "Epoch 887/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 888/1000\n",
      "0s - loss: 0.1030 - acc: 0.4218 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 889/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4244\n",
      "Epoch 890/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 891/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 892/1000\n",
      "0s - loss: 0.1031 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 893/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 894/1000\n",
      "0s - loss: 0.1030 - acc: 0.4233 - val_loss: 0.1025 - val_acc: 0.4264\n",
      "Epoch 895/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1023 - val_acc: 0.4273\n",
      "Epoch 896/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 897/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 898/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1023 - val_acc: 0.4275\n",
      "Epoch 899/1000\n",
      "0s - loss: 0.1030 - acc: 0.4198 - val_loss: 0.1025 - val_acc: 0.4277\n",
      "Epoch 900/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4236\n",
      "Epoch 901/1000\n",
      "0s - loss: 0.1030 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 902/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1023 - val_acc: 0.4269\n",
      "Epoch 903/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1025 - val_acc: 0.4277\n",
      "Epoch 904/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1025 - val_acc: 0.4270\n",
      "Epoch 905/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1023 - val_acc: 0.4259\n",
      "Epoch 906/1000\n",
      "0s - loss: 0.1030 - acc: 0.4207 - val_loss: 0.1024 - val_acc: 0.4261\n",
      "Epoch 907/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4270\n",
      "Epoch 908/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4278\n",
      "Epoch 909/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4264\n",
      "Epoch 910/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4275\n",
      "Epoch 911/1000\n",
      "0s - loss: 0.1031 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 912/1000\n",
      "0s - loss: 0.1030 - acc: 0.4232 - val_loss: 0.1025 - val_acc: 0.4267\n",
      "Epoch 913/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 914/1000\n",
      "0s - loss: 0.1030 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4275\n",
      "Epoch 915/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1025 - val_acc: 0.4245\n",
      "Epoch 916/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4253\n",
      "Epoch 917/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1023 - val_acc: 0.4272\n",
      "Epoch 918/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1023 - val_acc: 0.4267\n",
      "Epoch 919/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1025 - val_acc: 0.4278\n",
      "Epoch 920/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1023 - val_acc: 0.4263\n",
      "Epoch 921/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1023 - val_acc: 0.4274\n",
      "Epoch 922/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 923/1000\n",
      "0s - loss: 0.1029 - acc: 0.4233 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 924/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 925/1000\n",
      "0s - loss: 0.1030 - acc: 0.4211 - val_loss: 0.1023 - val_acc: 0.4277\n",
      "Epoch 926/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 927/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1023 - val_acc: 0.4275\n",
      "Epoch 928/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4242\n",
      "Epoch 929/1000\n",
      "0s - loss: 0.1031 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4276\n",
      "Epoch 930/1000\n",
      "0s - loss: 0.1030 - acc: 0.4235 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 931/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1025 - val_acc: 0.4273\n",
      "Epoch 932/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4279\n",
      "Epoch 933/1000\n",
      "0s - loss: 0.1030 - acc: 0.4220 - val_loss: 0.1023 - val_acc: 0.4276\n",
      "Epoch 934/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 935/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1024 - val_acc: 0.4254\n",
      "Epoch 936/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1023 - val_acc: 0.4272\n",
      "Epoch 937/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 938/1000\n",
      "0s - loss: 0.1030 - acc: 0.4207 - val_loss: 0.1023 - val_acc: 0.4272\n",
      "Epoch 939/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1025 - val_acc: 0.4280\n",
      "Epoch 940/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4259\n",
      "Epoch 941/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1024 - val_acc: 0.4279\n",
      "Epoch 942/1000\n",
      "0s - loss: 0.1030 - acc: 0.4235 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 943/1000\n",
      "0s - loss: 0.1030 - acc: 0.4234 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 944/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1026 - val_acc: 0.4262\n",
      "Epoch 945/1000\n",
      "0s - loss: 0.1030 - acc: 0.4241 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 946/1000\n",
      "0s - loss: 0.1030 - acc: 0.4233 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 947/1000\n",
      "0s - loss: 0.1030 - acc: 0.4225 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "Epoch 948/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 949/1000\n",
      "0s - loss: 0.1030 - acc: 0.4239 - val_loss: 0.1023 - val_acc: 0.4269\n",
      "Epoch 950/1000\n",
      "0s - loss: 0.1031 - acc: 0.4226 - val_loss: 0.1023 - val_acc: 0.4281\n",
      "Epoch 951/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 952/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1023 - val_acc: 0.4273\n",
      "Epoch 953/1000\n",
      "0s - loss: 0.1030 - acc: 0.4233 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 954/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 955/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1024 - val_acc: 0.4285\n",
      "Epoch 956/1000\n",
      "0s - loss: 0.1030 - acc: 0.4235 - val_loss: 0.1023 - val_acc: 0.4285\n",
      "Epoch 957/1000\n",
      "0s - loss: 0.1030 - acc: 0.4232 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 958/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4263\n",
      "Epoch 959/1000\n",
      "0s - loss: 0.1030 - acc: 0.4233 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 960/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1023 - val_acc: 0.4276\n",
      "Epoch 961/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1023 - val_acc: 0.4244\n",
      "Epoch 962/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4245\n",
      "Epoch 963/1000\n",
      "0s - loss: 0.1031 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4282\n",
      "Epoch 964/1000\n",
      "0s - loss: 0.1030 - acc: 0.4208 - val_loss: 0.1023 - val_acc: 0.4285\n",
      "Epoch 965/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1024 - val_acc: 0.4278\n",
      "Epoch 966/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1024 - val_acc: 0.4233\n",
      "Epoch 967/1000\n",
      "0s - loss: 0.1030 - acc: 0.4216 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 968/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4279\n",
      "Epoch 969/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4269\n",
      "Epoch 970/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1024 - val_acc: 0.4255\n",
      "Epoch 971/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1023 - val_acc: 0.4278\n",
      "Epoch 972/1000\n",
      "0s - loss: 0.1030 - acc: 0.4236 - val_loss: 0.1025 - val_acc: 0.4280\n",
      "Epoch 973/1000\n",
      "0s - loss: 0.1030 - acc: 0.4213 - val_loss: 0.1024 - val_acc: 0.4282\n",
      "Epoch 974/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1023 - val_acc: 0.4250\n",
      "Epoch 975/1000\n",
      "0s - loss: 0.1030 - acc: 0.4210 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 976/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1025 - val_acc: 0.4260\n",
      "Epoch 977/1000\n",
      "0s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 978/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1023 - val_acc: 0.4274\n",
      "Epoch 979/1000\n",
      "0s - loss: 0.1029 - acc: 0.4235 - val_loss: 0.1024 - val_acc: 0.4274\n",
      "Epoch 980/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 981/1000\n",
      "0s - loss: 0.1030 - acc: 0.4230 - val_loss: 0.1024 - val_acc: 0.4280\n",
      "Epoch 982/1000\n",
      "0s - loss: 0.1030 - acc: 0.4226 - val_loss: 0.1024 - val_acc: 0.4266\n",
      "Epoch 983/1000\n",
      "0s - loss: 0.1030 - acc: 0.4229 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 984/1000\n",
      "0s - loss: 0.1030 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4271\n",
      "Epoch 985/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1025 - val_acc: 0.4274\n",
      "Epoch 986/1000\n",
      "0s - loss: 0.1030 - acc: 0.4222 - val_loss: 0.1023 - val_acc: 0.4270\n",
      "Epoch 987/1000\n",
      "0s - loss: 0.1031 - acc: 0.4219 - val_loss: 0.1024 - val_acc: 0.4268\n",
      "Epoch 988/1000\n",
      "0s - loss: 0.1030 - acc: 0.4227 - val_loss: 0.1023 - val_acc: 0.4286\n",
      "Epoch 989/1000\n",
      "0s - loss: 0.1030 - acc: 0.4217 - val_loss: 0.1025 - val_acc: 0.4257\n",
      "Epoch 990/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 991/1000\n",
      "0s - loss: 0.1030 - acc: 0.4212 - val_loss: 0.1024 - val_acc: 0.4264\n",
      "Epoch 992/1000\n",
      "0s - loss: 0.1030 - acc: 0.4228 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 993/1000\n",
      "0s - loss: 0.1031 - acc: 0.4209 - val_loss: 0.1024 - val_acc: 0.4272\n",
      "Epoch 994/1000\n",
      "0s - loss: 0.1030 - acc: 0.4224 - val_loss: 0.1024 - val_acc: 0.4260\n",
      "Epoch 995/1000\n",
      "0s - loss: 0.1030 - acc: 0.4215 - val_loss: 0.1024 - val_acc: 0.4282\n",
      "Epoch 996/1000\n",
      "0s - loss: 0.1029 - acc: 0.4238 - val_loss: 0.1024 - val_acc: 0.4265\n",
      "Epoch 997/1000\n",
      "0s - loss: 0.1030 - acc: 0.4214 - val_loss: 0.1024 - val_acc: 0.4284\n",
      "Epoch 998/1000\n",
      "0s - loss: 0.1030 - acc: 0.4231 - val_loss: 0.1024 - val_acc: 0.4259\n",
      "Epoch 999/1000\n",
      "1s - loss: 0.1030 - acc: 0.4223 - val_loss: 0.1024 - val_acc: 0.4277\n",
      "Epoch 1000/1000\n",
      "0s - loss: 0.1030 - acc: 0.4221 - val_loss: 0.1024 - val_acc: 0.4267\n",
      "CPU times: user 12min 20s, sys: 25.6 s, total: 12min 46s\n",
      "Wall time: 12min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# training\n",
    "###########\n",
    "checkpointer = ModelCheckpoint(filepath=\"weights.nn\", verbose=0, save_best_only=True)\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=500, nb_epoch=1000, verbose=2, \n",
    "                   validation_data = (x_test, y_test), callbacks = [checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VFX6wPHvSU8ISQidBEho0gIIkaYgVSkKLMqCbbFi\nAUGsKKxr13VdrKyKioriDxVRsQBKE1EUQi/Sa0ILAQIB0s/vj3MnM5PMTEIIBG7ez/Pkycxtc+7c\n5L3nvufcc5XWGiGEEBWDX3kXQAghxPkjQV8IISoQCfpCCFGBSNAXQogKRIK+EEJUIBL0hRCiApGg\nL4QQFYgEfSGEqEAk6AshRAUSUN4FKKxatWo6Li6uvIshhBAXlRUrVhzWWlcvbrkLLujHxcWRlJRU\n3sUQQoiLilJqd0mWk/SOEEJUIBL0hRCiApGgL4QQFYgEfSGEqEAk6AshRAUiQV8IISoQCfpCCFGB\nSNAXQpSfrAw4tre8S1G2ck7D7t9Bazi6C04c9Lzc8f2w6YfzWjSQoC/EhSU3C04f9T7/5GE4tqf0\n209ZCYe3lX79sjZtCLzW0gRIT7T2Ps+b/Hzv62ycBXuXmddrv4RNP57ZtguXLT8P0lOcn/fX9/DV\nnfBhXxP4X28N7/eC3GyYOx4Ob4Xsk3DqiFlm+o0m+D8VCZO7l74sZ+CCuyNXCFvYuRgiY6FKPChV\n/PKr/w/iu8Av/4aVU+Gx3RAaZebl5cKcx+DSm2FyNzPtqXT39bWG/WugVivY+4fZRsvrTE1z688w\n9FMICIL3untePy8X/F3CwfF9MPtRE9SO74O7f/Fc7tQtkHMKDm+BpA/hhs/gj3fgsjuhUjWzrn8g\nhNeAzbPhp3/Cvb+bsgDs+d38Pn0U8nIgMARCIp3bfzoKarSAS/pAvc6QugkObYT1M2HQ/6Bue9i9\nFFoNgW9GwoG1JqBWaww3fg5zn4AO98Bbl5lph7eY7fZ8EuY/Y14Pfh8q1wSdb97vXwMoSNtmjsEV\nY+HAOlP+Bt1g8X8g8zhkpkPTfpA0BWo0h5tnwuc3Ocv++xvmd/oeeM4aHUEp2LYADm1wLvfNPeb3\nvpXmewit4vm7LiNKn+lZ9BxLTEzUMgyD8EhrU3uq0QzCoiH7FCx7Fzrd7wxYOafNckFhkLYdfnkZ\nBrwBAcHFbz9tuwlUrkHH9bOzM8A/2BmwXCVNgSpx0KA75GbC87Wc8zqNgquf9/65a7+EmXdC/Stg\n9xIz7bbZUL+z+dzkJPigl/s6w/7PBIl6naBRT5g5AtZ+7nv/qsSZkwDAXQvg14nm+/rbO/BKY+j1\nFOz5E/q/Aq+2cF93wiETFFd8bE5Onw2FxNth1SdwZIdzucZXwdafoGEP2L7AOX349yYgZqbD9R9C\ncARkHoOv7ihazrbDof0Ic8L4bIjvfXJodi389Z3neVUbmQB+IQirBqcOe5/f4m8w5KNSbVoptUJr\nnVjschL0bSrjkLmUr9oIqjVyTt88xwSTkIiz/4y8XNj0HTQbaGowJanRHt9naklR9UxgLmzjLIiq\nC3UuNe9PpoGfHwSFw9ov4Nv7zPSe/4L0ZEj6AAa9AzWbm319oY6ZP3aDCYS7fzPvJ6SaWl52BtTr\nCCkrTOC6bbapAW79GaZdb4Lo7XPMd1e9qbOME1vA8WTz+t7foWahoPiUdaK4fAz89nrR/Rp/AJa8\nav6pazQz0w6shzX/Z2rIOSchJhFSrL/9ep1g0NsmJbC5mLzvjV/AZ3/3vcyZCKsKp9Lcp933B6ye\nBr+/WXafI4qq1Qru+bVUq0rQr+heS3Dmfp9KNznFg+vgvR5FaxOpW0xKoP7lULWhc/qWn0wNuVaC\nqVmDyUke2wPxXU0O8uA6Mz32MpPKuKQPpO0wqYiI2s5tLXrJBNupA53ThnwMLQY53+dmwXM1zOuA\nELj2Dfh6hPN94h3wx6Si+xocAVnHi/lCFGD9rSfeYU4WDlUbQ9pW5/sH/4KJzUyt7OavTGpiYjP3\nzfV+xsxv8TdTs385vpjPd9HxPoiqb1I2vrS+wZwUyku3x2HFR3BiP9z6I/z6invt/ULV7FpTEZl5\nZ9F5IZHmZL73T+j7MmxfCFtml91nh9eC6HjYs7R069dpCyMWlmpVCfp2tvNXqNUSgipDfg4EhprL\n9snd4Pa55g961v3O5ceshR8ehG3znNMmpMKJffDZMEj9y0yrXNsEvA/7Qau/w/cPOJdv0A12LHJ5\n3x12+PjjjKwL9y01l/pR9eH9np6Xi6pncpih0b63dzGqXNsEzJIIreK7Abc8DPkIohvAu13P7ec0\n6Ob+t+VNcCRkpRed/tgu+Heced18IAy0KgYvxhZdtlINU/n4axYMeBNaDXPm2zuPNu0Bqz91Lt/7\nWfj5n+Z1lXgY/p1pePak82i46lnz+tf/OtsMvBn8Hsy8y33ag5vcK0tnoKRBX3rvnG/Zp0we1Rut\nTe+DRS/BwQ3u8w5vhWXvwcfXmB4B066HNxNh3QzTS+D0UZj9mHvAB3i9lXvAB5Mjfr21M+CDCVCT\nOpjGNdeAD0X/KYsL0Ol7zT/ijNu9B3wwVw3719gv4APcOc8ElpLo+eS5K0fsZXDTV873DbpDXBfz\nuuNIuHuxCe6FhUSZk/HZ8gv0PT+xUF6/bkfz21FGgOs+gNZD3Zfr/18YvdqcMId/BzVbQr//QnBl\n83Onh6sSpUBZYS8g1L19pvczzsbz6k3hb+/C5aOd8//xrUk9Fin/7aZi5Qj4AF0e8r6/N30FYzea\nVA6YVObg902bSuVa3tcrIxL0z4XkJBPI8vPg85th1xLTF/n0MZNeeb4WvFjPdPVKWQHznjY54Vmj\n4Zv74JkqsOhFeLuzqXVv+cmcDN5KhB8fNp+Rts0EyuPJZj2HkgbP/Ws8Tz+8+ez23VV+rvN1VD33\nebcW01Vu0Nul/9zASvDAOmhzE/z9E8/LVGsCTfq6T4usC1c9V/rPBRM8r/vA/CNHxEDbfzjnjVlj\nyuRJ9inv27znN3jyqNmv4rS8zvm673/M77wc99rjlY/CNa9Cwt+h17+gdmvP2/IP9N6TpNMo87tW\ngvey9P+vOc5j13ueX7uN+V2/s/v0CKtdptvjcEl/U8NPuN78PzmE1zI9hKKttFp8V7j3Nwh3eYZI\nbDsPH+rS9lS4DUop52e0HQ6th7nPr1To+STXfwg9/mm+yyr1Pe+jg+v32LgXRMZAjabmuI5YZHof\nXTG2ZO1iZ0m6bJaVU0fgu9EQ3RB+e81MG7nc9Cjw1KsgKx1ebe4+beXHRZfb/ZuzMdKbnJOm1pJb\n6AriigdhyUTzOrY9JC9zn99pFCx9y7z2CzA/uZm+P6uk2txc6DL5GfjyVvN63F5TE3Po+qjJqx5Y\n55xWqUbRbQ5403kVM/B/zkZdV67tBIP+B1vmmteNekGHe2GaFRQHToKFhXrU3Pi5aaDtfL+zYdZV\no15Fr5gKyzxuAlTC9c5pTfrAljkQWc+UKSIGFr/svl7c5d63WaW+acy+ZSZMudqcQG/6ymzzeIrp\nMbNtPmSfMEF//VfgH+TcZmCoCZIOQeGm8fq69zx/Xr9XTOWiShwEh0Oj3rDtZ/dlej1tGs5bD4Pv\nHoANMyEv232Z5oNMb6h8qytkRKyzMRxMDyKtTc+r+1fCm22dn1+vo2nMdv1eXAPr9S5tMmfCtabv\n6KLpKj/H/PbzEBoLdzxoObjkn9u0v0klFd6u3/mvd0vQPxPpySa/ecVY0y931aem10fd9ubMXTi4\nT7rs7D6vxd9gw9clW/by0dD9CUjdDJPam2kd7obu480fuZ8frPzE9HOu3tT8sx5cb4J+u9vMCcCR\nu+36iOmL7MlVz5s+4Ic3w21z4MM+znmRdU1aByDxNvegX8M6wV3xoLPnUHRDE5x6jDc/L8SawNXr\naYhNNDnxvi+bGtbMu0y+dtb9Jmg5/jkdwqrCHT+7N0SDqQG2GGxqtJVrQ+OrTU03NhFyrBNcp1Fm\nPdceObf+CB/1M68bXw09Jjh75XjqdufoQePnX/Q7G/KRORk4/sG1S401qp65KoGi3RwB4q90niDr\ndYR/pjm7p1Zv4lyukZVCy8s1KZvO95tUQffxpkG4UlXnsgEhRctYr7PpetnzSVODbj3M+bk3z4Cn\nq5ggOXoVVK5jypB4m5k/+F3z8/EA2OnSnz8w1Pz284MRv7DkcBitagQS8Y5Vw/fzJzcvH5Wv8a/a\n0JzIwqqYsna4u2gZO42yrtD6+KwR5+Vrvl2dwsA2MRQ9Gsr6wXlDVcvrnVe+jqtT13sWrnnVfK9u\nm3Hf8jerUli0+RDdm9ZgYJsYM7H7BFhoXTkqP9PV1Yt9x05To3IwAf7n/iQgQd/VX9+Zg9O0v3Wz\nSK6pqRzcYILTZ0NMV7afJrivt31+ybZfK8HUZuOvNAGowZXm7rw1082JZP0M88+astL8w5444Dvo\n3/4TzHvK5OAjrUar6pc4a6ShVdz/eNve4r5+nUvhroWmXP6Bzn+kdrd5DvqP7TLbXD3NvHetrQMM\nfAu+vsecfGITYfxB0w970/cmcP8zzT0ojlpOwT8gOGteLa8zudWHNjnnOVIEN3xuLouTCzX2B1cu\nGvDBBJ4hHzrf3/SF83WOlVJpcrU5ObiKu7zoDUyOHkx128PmQumpKvGmt1Gsh3a0wFBnAATTcPnr\nf83rTi7tL7dYx3rXb+Y4VqpWdFv+xfzL+gdAnxec76981Pm66TXmWASHF12v/3+Z7tcXglsxTKmi\nx9ZxbMJrmhuoLD+s3c+p7FyGJNYtGogDnPv8R2Zdbv7sD/o2r4pr4q7R+Nl0aVyNT+7oYNIevvj5\nwyV9fS8DfL58L098vY4Hv1jDrusmmk4MDko5/04cJ0LrqiH56CliAkLNX2SQy3eUeDsAWms27DtO\n80d28unyZAZn5RIeHMDa5GM88PlqAL5ZvY89aafYeiiDIYm30qV/NPzwIMcz85jwf6t4ekALXvlp\nM4/2aUpkqGnrSD+VQ+eXFnBr5zieGlCoK/A5IEEfTM+XqPom/w7w6E7TBa96M+jyYNEW9jN122zT\nKJaSZGqqYdGmZuTQ3tp+s2vM7xgrF3n6qPkndTSi9n7W1OjfucKcPAKCTLAG95zhkI/NPpXkhqSY\nts7XHe81wb5Sdc89Txyf4W81frleqjoCpGugDgwxjWEHNzgDpqvCtWJHYPEUlBwusa4sIuuZ8jlO\nwC4BpsRys8zvkKiSLd/1UfOZ17wOC5/jZP3eBNZsRNCpVFPrdq15u1iy9TC/bkvl4asuIcBPoVxP\nMB1GFF3BQ6onP1/j5+c73/vNqhT2HDnF6J6N3aZn5uRx/HQONQa9DSl3sORgEHf+ZzYf3daejg2s\nwBcYwrjfFbCOYe3d21+OZ+ZQ6cavyF0+hbbPLaZHs1pM/HtrAv39GPnZSgD+2n+Cx/M0bk22fn4c\nzsjisufnFVSqZ29Mg0IXGr9uPcyc9Qfo09K9ETMrNw9/pQjw92PWmn08PWsDn9/diUY1iv59rE9J\nJ7pSEH/tP87yXUcKps/deIirgd90Ky5Xa8n3D+aaVR25Mf7frF9dnWNLV/DUgBZsPniC4VOWMem6\n2+nfvaq5OgRem7eF37Yd5pM7OtDpxfkcPZXDfd0a8r9Fe1mbqjl0IovFW1LdyvLfn81dv7PW7GPO\ndfVpCkzeG8Os1H0czsji9+1pTPtzD6v+2ZtHv1pLTJT52/3o9108eU3zYo/z2ZIum0teNbVlV9Wb\nufdqKcwx//6Vpn/4Z8Mg40DR5Rp0MwHY0SPg9FH44Gpzx2PhmmVxThwwwdjP39QEf3wE7poP/zfM\nnBRu/srU8M+GYywR/wDT8JxvXek4ur45AvuRHeYO1F7PmEZn13lnIe+3N/H/eQLpjxwgspL5R1if\nkk7D6uF0emk+L1/XiqtaOANDZmYmIS/VNG/uX0l+lQY89tVahrWvS7v60Qx9dymbDpxgzb+uAiAt\nI4s5Gw5wY/t6KKU4/Z8WhJ5MhtGryIuK551ftjO4bQy1I0t2Aokb9wMd4qN5cXACPf77C9NHdKRj\ng6ocSM/k540HCA8J4P1fd7Jhn/MegjuuiOcfnepT/806Bd/b+pR0bv1wGdGVgmhZJ5KJQ03642RW\nLhN/3kJQgB+f/rGbx/s244mvTSroszs70LlRtSLlAejSuBo3tK/Hyt1HubZ1HR6dsZbNB0+w66X+\nbssBBdN2Hj5J91cWAbB8fC9embuZvw4cp1ezmkz8eQsjuzdk84EM5v1lBg+bPaYLzWpHuG1rbtWJ\nXHIyiXuzx3AouD4t23QgT2s+/cN9rKBfB+cSeGQbU+nP/xZtL5j+zs3tyMrNY8z01Qy+NIaZq1IA\n+Gbk5Qya5GzXur5dLD2b1iAsOIDmtSM4kJ7JtW8t8XiMWqhd/BD8BCOzR9PCbxcz8rqyQ9cpslz7\nuGiWWSeLHS/0w89PcexUNm2eMW0ZoYH+nM7JK7JecVrXjWLK9fVo9+raIvP8/RR5+e7x9+exXWlc\ns3KRZUtC+un7suZzkza5fLQZ9OhMPbbbBEfH5eHE5qZBrbCm18CwaWdX1uI4br+/9QeIuwKAtcnH\naForgqCAMsoPOho1n0pHa41yvYy35mVPOMrJrFyqVAqixyuLqBMVyqd3dvC52W2HTvBFUjLj+jRl\ndfIxBv/v94J5MVGhjOnVmEdnrOXurg14d/EO6kaH8uujPRj8v984lZ1HRHAAXxzsy+z8jjzMWFrF\nRrF0h7mT9NE+l/DyHNMTafWTvYkKC+KOj5Yzf9Mh5j7QlVqRIcx4/hbuCJjN1tv/IulALo/PXEel\nIH/WP311wT6mZWRx64fLOZWdy/yHuqG15sXZmxjUJoZ+b5g7J+/v0Yg3F2yjWe0I/tpf3E1ixo7a\nE/A7uoOt9yYz8ectzF7vrDSsefIq1iQf4/X5W1mx23Pf/biqYcx/qBufL9/LU99t4I1hbbjn05U+\nP/OnsV2ZtXofby30PSRBw+qV2J560ucyTw9owY0d6tF4vPPGpvv8v+XRwM/pmfUftusYr+smxERy\n8Hgmh05k+fyMshLOKTLwcPe3F2N7NeHbNSnsKOY7cHVr5zg++n1Xwfurmtdk4eZD5OSdWXx9ekAL\nhneOO6N1HCToe7Lmc9PQuOBZz/P/PhW+cOliN3o1vGE1Oo0/AF/fbW7/L5w7fr+36Rlz/RTTOLnq\nU1j+3vkJ+qePwerPTGpGKfYdO03nlxZwQ/u6vDi4FVprZqxIpm9CbcKDS5nNO7aX9OPprM6syfAp\nyxjRtQEjujbgm1UpdNRraRmVze0r41mw6RCXN6rKb9tM4HXUIgE27jtOjYhgqlYKQinFN6tSCvKg\nCx/uxn3TVnoNmCGBfmTmmNRPr2Y1mPfXoYJ5VTjOCcLILSZT+eQ1zZm5Kpn1Kcd5rE9TmteJ4PYp\nS4kigzTce+r8Pq4H36xOQWtzyZ1qBacptyZSKSiAoZP/OMMvsKiWNUPYevA4reNqUaVSIHM3OIff\nHdm9IZMWbvexNgT6K65sUt3tuyhvinxiVSp7dc3yLkoRTWqGk5mTz54j3rvGBgf4kZXroUePRSnv\ng3c+2LsJE620DsC8B7uyaHMqz/3gOWMQFOBHtofPurFDPV74m49usD6UadBXSvUBXgf8gfe11i95\nWe46YAZwmdY6SSnVG3gJCAKygUe01j7v4z6nQd9TNzy3+emm66Xjlvqn0k0Pj+yT7r0fCju+34yP\ncpl12/eGb+DL4dBsAAz10k+8FE5n5+HnB8EB/gXBfECbOgQHmNx4Tl4+mw+c4Jo3l1C/ahi/PNKd\npF1HuP6dpfRpUYu60aE8dNUlBPn7sXRHGi3rRBIYoAj09yPQ3w+tNZ/8sZvmtSNIjDM5+IysXN5b\nvIPX5291K0unBlULatV1IkPYl+65q+c3Iy+ndWwk8Y+bhs/28dE81LtJkcAZFRbIsVM5njZha10a\nV2PboQz2e/n+zqczuVI5E8Muq0u3S6rTvHYks9ak8MpPWzwu17FBNH/sOMKo7o0KrkaqVw4m9UQW\nVzWvyU8bvYxL70GAnyLXSp04UiZHT2Zz6bM/e11n9pgu9H3d87g3QQF+bH62T8Hf8e/jerA2OZ17\nPl0BwIT+zdieepL/W2ZSWX8+0ZP96ZkFaam7usTz3q87C7Z3c8d6RdJe4F5ROlMlDfrFVv2UUv7A\nJKA3kAwsV0rN0lpvLLRcZWAM8KfL5MPAtVrrfUqplsBcwPt1X3kaZQ4eYdFw71JnuiYwxK23gkcR\ntZ0BH5wNkqr06ZXNB04wefEOXrougUB/v4L8YkJMJO/c0o4f1u7jhR83sTvtFA9ffQkns3Jp8a+5\nBevvTjvFsVPZBYF0zgaTPogKC+KDJTs5cjK7yGdGVwriyMlsYqJCeWFwAs98t4H007kczih6Ge4I\n+IDXgA+45WIBlu084rGmfLEG/OXje3HZ86bv/qA2dfhm9T6eHtCCf81y3k099fb2vLlgK8t3FU3V\n/LrV2fXzpg71qF45mNfmmRPs3Ae6snLPUWat3seeI6dIOebjTm7LLR3r83i/phw6nkU3K0cPUL9q\nGLvT3Gu53468nDXJx3jyW1PWf17TjBvfc/77ekrzfHF3J07n5PHe4h0s2VZ0tMiFD3cjvlol8vM1\nD3+5hpmrUrizSzyNapg89d8vq1sQ9P98oidPfru+4Crnxg71mT6iE0BB0J95b2fqRpvUzJdJe3lk\nRtHcuMPQxLqMv6YZESGBTF+2h3EzTftHZJhpXq5SKYh5D16JUtDzv+5DRTvy+N5c3aIWSiluaF+X\n09l51IkKpU6Us+3npg71CQ3yZ++RUyzZdpiIkECqVnLe7Tu+f3PeX7ITreGvZ/oQ6K/4R6c4/tp/\nnDHTVxNTgnRoWSm2pq+U6gQ8pbW+2nr/OIDW+sVCy70G/Aw8AjystU4qNF8BaUBtrbXXZN45q+kf\n3mruaC2s/d3mLkxPw+WW1pafTPfO9iOgn5f+7pbT2XkcOpHJB0t2sj01g2l3mlvQB036jdV7jzHz\nvs4kxEQyYmoSCzenFll/SLtYjp7KKWhgu5i4Np4VVqNyMJ0aVqVprQj+PWeTx2VeHdqaH9cdoGWd\nSF6d57n2CKYx7b1/tONkVh5RoYFea3uTb2nHnzuP8MGSnR7ne7Lrpf68MX8rlUMCuO1y56BrYz9f\nzddWQ+T0ER1pV78KvSb+wu60UzzRryn1osPYejCjoKcHwPYX+uHvpzh0IpOMzFwaVHf2Utl5+CRL\nth1mzvr9/D2xLn5KMXfDAb5f6+xhNbBNHV4fdmnBe0cja73oMBY/2p2jJ7PZlppBkxqV0Wiiwszf\n/PHMHL5YvpfbL49nutXdEUyKotfExbw2tA0PfL6ahJhIvrv/ioLtL991hG9Xp7jVWLc937egr3le\nvuZwRhY1I9wrTXn5mrx8XdDmdNfUJH7eeJB3bm5Ln5bmzuEpS3by2bI9zBnTxa3velZuHhv3Hedv\nVvvPmJ6NeX3+VuY+0JVLajkbQLXWbE/NIC8ft+kO7/+6g26X1GDVnqPEV6tUcGXr+M5eHJzA92v3\n8erQNhw6nkWjGuGEBBbt9T9rzT6yc/O5vp3p7JCRlcuWgydoW890cPgiaS9VKwXRs1lNcvLyOZCe\nWXASc9h75BTVwoMJDfJwj8cZKLP0jlLqeqCP1vpO6/0tQAet9SiXZdoC47XW1ymlFuE56F8P3KO1\n9tnFpEyCfk6m6a7oocGRXk+bccg3fmvukHPtOllKuXn5vDh7E3d2iTc9P7Q2ozi2vgGCnLfOf7s6\nhTHTV7NiQi9SM7J48PM1BAb4sWbvsYJlvrq3E+3qRzNs8lL+2GECoq9cYpOa4Ww5mHHW+1Ac18tl\nT6qFB3E4I5uODaJ5beilXPvWkoJcOJha2OdJzsfiXVKzMnPHduWy5+e5LQdFL3FPZOZwOjuP95fs\nZPJiM3b72F5NGNm9YUFAcO1FUtgLf0vgxg7Obogrdh/hurfNKIj9E2pzab0o7uziHHsmNy+fPK2Z\n+vtuIsMCeXTGWqpXDqZedBhRoYEs23WEE5m5Hsvq6tetqdz76Up+G9eDyNBAFmw6yCNfruXXx7oT\nFhRAbl4+jVwaQs/00v50dh7NnpxT8P7urg14vJ9zNFDHdzKqeyMevvqSEm0zOzefJhNmExUWyOon\nryqYPnfDAbo0rkZYkOfkwCdLd/HTxoOmv/0Z2nzgBI/MWMOnd3YgIqSYcXosizYfIv10DgNa1+FU\ndh6VStteVYjjOzubNEt5OW9BXynlBywAbtVa7/IU9JVSLYBZwFVa6yItVEqpEcAIgHr16rXbvXt3\nyfbSk5Np8J8GpvbeaRTMf9rcwTflanMn4mO7YPkH8NN4U8vv93KxmyzOr1tTueWDZVzRqJrPS7QB\nby1hbXI6X9/XmcVbDnutnW57vi/3TVt5RjnMs/HWjZfSp0Utnpy1AT9FkVxjTFQo8x+6kqb/NAHm\nq3s78dAXa9hlpQteHdqajg2qMvh/v/PePxJpGeNsO0k/ncOqPUfpdkkNnvx2PVOX7mbJY92JrWJq\nO3uPnGLiz1uIrRLKmwvMJb2vf7jG43/kzi4NeKxPU7fpjn/W7S/0Y/Xeo1z39lKeHdiCiNBArm1V\np8il+94jp4iJCj3jPtFaa/I1fLZsDzUqB3N1i1rFr+TDpgPH6fPar/RvVZtJN7YtfoVCVu05SoNq\n4czdeIABreu41UZHfbaSdSnpLHyo2xnt59Slu+jcsGpBSqYiWbjpEJsOnODebh5u9LvAlWXQ95ne\nUUpFAtsBR3WzFnAEGGA15sZiTgq3aa2LGUSmDGr6u5eaoQFiEs3t444hVwGGfWbutj22Fz7obZ7m\n4/qAkVKas/5AQYPO+/9I5MsVewkLCmBsryb856fNDGpTh/3pmUz4xtxV+lDvJkxevIMTWbm+Nlti\ntSNDijQEju3VhFfnbaFlTATrU5yNc3deEU/T2hFsO5TBO79sJyYqlN/G9XBb97dth7npfWdu9/G+\nTbn7yoYFgdVxCX/tm0tYl5LO68PaOG899yEvX7M//XRBwC/sia/XUTsihPsL3VxUEo50mOOEceh4\nJjUiimnI05PxAAAbF0lEQVSLuUCczs4j0F+dl1vwhX2VWUMusBxorJSKB1KAYcCNjpla63Sg4C4R\n15q+UioK+AEYV5KAXyZOWnnvkAhY9G/3edWt2mFUXfc7R0thfUo6QQF+NKlZmR2HnemVO6c6T1iO\nnO53a/a5reuaxy0LnRtWY9muNPYeOc3tl8fTPj6a6pWDeXXeFhpWD+e2zvG8Pn8rb95wKa3rmhvF\ntNaEB/vTL6Ho2N0d4qNpVCOcvyfG0rhmZa5s7D66oCM4fXJHe95csK3EtV1/P+U14AOl7qoGMO3O\nDm6N0xdLwAfOOpcrxJkoNuhrrXOVUqMwPW/8gSla6w1KqWeAJK31LB+rjwIaAU8qpRwDhl+ltT53\nnYsdA35tX1B08KoqcWe16eOZOew7dpqmtSK45k1zB+CW5/ry81mmYQa3jWHmypQi3RZfGpxQ0APh\n9svjCQ3yY83edDo1rMoPa/eTdjKLVrFRjO/fjHyt2XX4ZEGDFMC7t7SjZUwkMVGhXNfO/YESSilG\n9fBcow7w92Peg1cWmf6/m9qyaLPz0EWFBfHPa5oXWa48VAoOKLO8rhB2Zr+bs76+x/sj5ko4VECR\nu06BH9ft575p5o7HxY90p+t/nOPWO7o6Fqd385oFJ4h3bm7LJ3/s5rdtaTw7sAWD28bi76dIPnqa\nKmGBvLt4Bw/2bsIV/17I4Yysi7JhSQhx/lTcJ2elJxe/jA/rU9KJf/xHt0GbgIKAD7gFfIAjJ7N5\nvG9TburgPlAVmFvfAZrXjuDNGy6lbnQo7/8jkT4ta/PPa5pzS8f6DLw0hkrBAYQE+tOoRjhVw4N5\nol8zQgL9mT2mC9+7dJMTQoizYb/r4Yyzyxwt3GTW//QP04Pol82pxY5V0qtZTYZ3juNwRhbT/nTv\n+dKkZmXeuvFSujSuTkigP78+6mw0bVorgmcHeXnepqV65WCqVy7BaJlCCFEC9gr6+1ad9eP+jlo5\n9W9X7+Pb1fuKzI+rGlbQVdHh/eHmiiq2SljB4Fsz7ulUMNjSNa2KjuonhBDlwV5Bv/CDxM/A6ew8\nOr80n5NZnodPrRkRzMHjWTSuWZmFD3dDKUXcuB8IKtTN7oFeTbiubSxx1UrwPFMhhDjP7BX0PT0G\nrlJ1ZzdOH7YcPFFQy/dkQv/mLNqcypiejQsaeb+//wqiK7kP3+DvpyTgCyEuWPYK+oUfzAzmYSXr\nv/K52oH0TLYdcva1jwwNJP208wTQo2kNrm1dh2tbu6dpXO88FUKIi4G9gr7j8XejV8O0IZC21XPt\n38X6lPSCPvcOrWIj6dWsJs3rRLD9UAYD2khOXghhD/YK+o6afnCEc6Azf8+jZ+bk5dN4/OyC51O6\nGtC6jnnQM3BZnIdnuwohxEXKXkHfUdMPCHIGe8fDwSPrui3quJnKMUZ5rYgQlj7eg4ysXCqXcKQ/\nIYS42Ngr6OdZQd8/CPysXQsKhyf2mweKW7Jy89h84ITbqn880RNAAr4QwtZsFvStxlf/IOcJIDQK\ngtwH+Ro5bdVF+dARIYQ4W/YahiE3ywR8pSDbuoEqJMptkaRdRyTgCyEqLHsF/bxs8Ldy+DnWsz1D\n3LtV3vrh8oLXlWRIWyFEBWOv9E5ulvNZt46afqh7TT/D5cElb954KQs2HfI5xrsQQtiJDYO+1S8/\nx/TKKVzTDw7wIys3H4AeTWvSo2nN81lCIYQoV/ZK72RnOPvnF6R3TE0/MyePkdNWFgT8h69qUh4l\nFEKIcmWvmn72SWfQd7DSO9OX7eGHdfsB8xzbXs2lhi+EqHjsVdPPOQWBhYJ+UGUAMq0aftNalenZ\nrMb5LpkQQlwQ7BX0XdM7/V6Bmi3Bz+xi6oksQgL9mD2mS5FHIQohREVh3/RO+7vMD3DweCZLt6fR\nqEa4BHwhRIVms5r+qSJ332qt6fDCfDbuP05ifRk8TQhRsdkr6OfngJ/72DmOAdUA7u/R6HyXSAgh\nLij2CvpamyEYXBw/bW7GeufmtlQNlweMCyEqNnsFfTSgOHQik8MZZsA1xx244cEyeqYQQtirIdeq\n6bd/fj4Au17qz/TlewAID7HXrgohRGnYr6av3Hdp5soUAMKDJegLIYS9gr7OB5w5/S+W7y14HSoj\nagohhN2CPm4NuY9+tRaAhJhI6kT6fkC6EEJUBPYK+mh0oSm3do7ju/uvkJuyhBACuwV9rbGG2Clw\nS6f65VMWIYS4ANmsdVOTnWfq+uP7NePqFrWoV1UekCKEEA62q+ln55mXNSKCJeALIUQhNgv6+eTk\nm5p+ZemXL4QQRdgr6KPJzjVBX+7AFUKIokoU9JVSfZRSm5VS25RS43wsd51SSiulEl2mPW6tt1kp\ndXVZFNor7czpy81YQghRVLGRUSnlD0wCegPJwHKl1Cyt9cZCy1UGxgB/ukxrDgwDWgB1gHlKqSZa\n67yy2wVXuuAJWZLeEUKIokpS028PbNNa79BaZwPTgYEelnsW+DeQ6TJtIDBda52ltd4JbLO2d25o\nTWpGNpWDA4iJCj1nHyOEEBerkgT9GGCvy/tka1oBpVRboK7W+oczXddaf4RSKkkplZSamlqignum\nOZGVT72qYfj5yc1YQghR2Fk35Cql/ICJwEOl3YbWerLWOlFrnVi9evXSF0bnk5uvCQmUcXaEEMKT\nkiS+U4C6Lu9jrWkOlYGWwCJrqINawCyl1IASrFu2rDtyg/xt1ilJCCHKSEmi43KgsVIqXikVhGmY\nneWYqbVO11pX01rHaa3jgD+AAVrrJGu5YUqpYKVUPNAYWFbme1FAk5evCQ6UoC+EEJ4UW9PXWucq\npUYBcwF/YIrWeoNS6hkgSWs9y8e6G5RSXwAbgVxg5LnruWPk5ENwgAR9IYTwpET9GrXWPwI/Fpr2\npJdluxV6/zzwfCnLV3La9M/PzYegAMnpCyGEJ/apEjuCvpaavhBCeGOf6KjNTVk5+ZogCfpCCOGR\njaKjM70jNX0hhPDMPtHRSu/k5EGw5PSFEMIj+wT9gpq+pHeEEMIb+0RH7Xg6rpL0jhBCeGGj6GiC\nfr4EfSGE8Mo+0dHqvaMl6AshhFf2iY5WekcjDblCCOGNfYI+jqCvpCFXCCG8sE901M6gL+kdIYTw\nzEbR0SW9I6NsCiGER/aJjgU1fT+C/CWnL4QQntgo6Dt670hNXwghvLFddNQoeXKWEEJ4YZ/o6NKQ\nG+AvD0UXQghP7BP0XRpyA/xstFtCCFGG7BMdXWr6/n5S0xdCCE9sFPSdwzAESNAXQgiP7BP0kZq+\nEEIUxz5B3yW9Eyi9d4QQwiMbRUdnQ67U9IUQwjP7BH3XLpsS9IUQwiP7BH2Xh6j4Sz99IYTwyD5B\nX3rvCCFEsWwU9HXBS8npCyGEZ/YJ+i5dNgPljlwhhPDIPtHRpSHXT2r6QgjhkX2CvlXT91MS8IUQ\nwhv7BH1HTl9SO0II4ZV9IqR21PTts0tCCFHWbBQhraAv+XwhhPDKPkFfavpCCFGsEkVIpVQfpdRm\npdQ2pdQ4D/PvUUqtU0qtVkotUUo1t6YHKqU+tub9pZR6vKx3wMnqvSMNuUII4VWxQV8p5Q9MAvoC\nzYEbHEHdxWda6wStdRvgZWCiNX0IEKy1TgDaAXcrpeLKqOzurJq+QoK+EEJ4U5Kafntgm9Z6h9Y6\nG5gODHRdQGt93OVtJRzVbvO7klIqAAgFsgHXZcuQ9ZGS3hFCCK8CSrBMDLDX5X0y0KHwQkqpkcCD\nQBDQw5o8A3OC2A+EAWO11kfOpsBeWWPvIOkdIYTwqsyqxVrrSVrrhsBjwARrcnsgD6gDxAMPKaUa\nFF5XKTVCKZWklEpKTU0tbQEcWyvd+kIIUQGUJOinAHVd3sda07yZDgyyXt8IzNFa52itDwG/AYmF\nV9BaT9ZaJ2qtE6tXr16ykhfhSO+UcnUhhKgAShL0lwONlVLxSqkgYBgwy3UBpVRjl7f9ga3W6z1Y\nqR6lVCWgI7DpbAvtUUFNX3L6QgjhTbE5fa11rlJqFDAX8AemaK03KKWeAZK01rOAUUqpXkAOcBQY\nbq0+CfhQKbUBUwf/UGu99lzsiKOmLyl9IYTwriQNuWitfwR+LDTtSZfXY7ysl4Hptnnuaem9I4QQ\nxbFPhHQ8OUuq+kII4ZV9gj6S0xdCiOLYJ0Lq4hcRQoiKzj5BPzqe92uMZ0dAw/IuiRBCXLBK1JB7\nUQiLZll4D45mnyrvkgghxAXLPjV9IF+DkoZcIYTwylZBHzTyDBUhhPDOVkHf1PTLuxRCCHHhslXQ\n11rjJ1FfCCG8slXQl5y+EEL4ZrOgr2WQTSGE8MFWQR+QhlwhhPDBVkE/X2tJ7wghhA+2CvpaS01f\nCCF8sVXQl5q+EEL4ZrOgL09LFEIIX2wV9NFIP30hhPDBVkHfpHfKuxRCCHHhslXQ10hNXwghfLFV\n0JeavhBC+GazoC/DMAghhC+2CvpoGVpZCCF8sVXQly6bQgjhm62CvkaGVhZCCF9sFfTz8+UhKkII\n4Yutgr5GGnKFEMIXewV9acgVQgifbBX0zUNUJOoLIYQ3tgr6WoOfrfZICCHKlq1CpNT0hRDCN1sF\nfdOQW96lEEKIC5e9gr4MrSyEED7ZKujLgGtCCOGbrYK+1PSFEMK3EgV9pVQfpdRmpdQ2pdQ4D/Pv\nUUqtU0qtVkotUUo1d5nXSim1VCm1wVompCx3wJVpyBVCCOFNsUFfKeUPTAL6As2BG1yDuuUzrXWC\n1roN8DIw0Vo3APgUuEdr3QLoBuSUXfHdaRlaWQghfCpJTb89sE1rvUNrnQ1MBwa6LqC1Pu7ythKm\nIw3AVcBarfUaa7k0rXXe2RfbM7kjVwghfCtJ0I8B9rq8T7amuVFKjVRKbcfU9Edbk5sAWik1Vym1\nUin16NkW2BfzEJVz+QlCCHFxK7OGXK31JK11Q+AxYII1OQC4ArjJ+v03pVTPwusqpUYopZKUUkmp\nqamlL4MMrSyEED6VJOinAHVd3sda07yZDgyyXicDi7XWh7XWp4AfgbaFV9BaT9ZaJ2qtE6tXr16y\nknsgNX0hhPCtJEF/OdBYKRWvlAoChgGzXBdQSjV2edsf2Gq9ngskKKXCrEbdK4GNZ19sz6QhVwgh\nfAsobgGtda5SahQmgPsDU7TWG5RSzwBJWutZwCilVC9Mz5yjwHBr3aNKqYmYE4cGftRa/3CO9kUa\ncoUQohjFBn0ArfWPmNSM67QnXV6P8bHup5hum+ecDLgmhBC+2euOXJCavhBC+GCroJ+fryWnL4QQ\nPtgq6MvQykII4Zu9gr4MuCaEED7ZKujLgGtCCOGbrYK+eUauhH0hhPDGVkFfavpCCOGbrYK+aciV\nsC+EEN7YK+jL4xKFEMInWwX9fC03ZwkhhC+2Cvpm7B2J+kII4Y2tgn6+RhpyhRDCB9sEfa3NExql\nIVcIIbyzUdA3vyXmCyGEd/YJ+tZvyekLIYR3tgn6+VZVX3rvCCGEd7YL+pLTF0II70r05KyLgeT0\nhbCHnJwckpOTyczMLO+iXJBCQkKIjY0lMDCwVOvbL+hLp00hLmrJyclUrlyZuLg4uXIvRGtNWloa\nycnJxMfHl2obtknvaCSnL4QdZGZmUrVqVQn4HiilqFq16lldBdkm6OdbNX3pvSPExU8Cvndn+93Y\nKOg7GnLLuSBCCHEBs03QdzbkStQXQghvbBT0rZp+OZdDCGEPgwYNol27drRo0YLJkycDMGfOHNq2\nbUvr1q3p2bMnABkZGdx2220kJCTQqlUrvvrqq/IsdrFs13tHGnKFsI+nv9vAxn3Hy3SbzetE8K9r\nWxS73JQpU4iOjub06dNcdtllDBw4kLvuuovFixcTHx/PkSNHAHj22WeJjIxk3bp1ABw9erRMy1vW\nbBP0C+7IlagvhCgDb7zxBl9//TUAe/fuZfLkyXTt2rWgq2R0dDQA8+bNY/r06QXrValS5fwX9gzY\nKOib3xLyhbCPktTIz4VFixYxb948li5dSlhYGN26daNNmzZs2rSpXMpTluyT00eGYRBClI309HSq\nVKlCWFgYmzZt4o8//iAzM5PFixezc+dOgIL0Tu/evZk0aVLBuhd6esc+QV+GYRBClJE+ffqQm5tL\ns2bNGDduHB07dqR69epMnjyZwYMH07p1a4YOHQrAhAkTOHr0KC1btqR169YsXLiwnEvvm23SO1pu\nzhJClJHg4GBmz57tcV7fvn3d3oeHh/Pxxx+fj2KVCdvU9GVoZSGEKJ7tgr4MuCaEEN7ZJuhLTl8I\nIYpXoqCvlOqjlNqslNqmlBrnYf49Sql1SqnVSqklSqnmhebXU0plKKUeLquCFybDMAghRPGKDfpK\nKX9gEtAXaA7cUDioA59prRO01m2Al4GJheZPBDy3ipQRGVpZCCGKV5Kafntgm9Z6h9Y6G5gODHRd\nQGvtep90JZzPKUcpNQjYCWw4++J6ly/pHSGEKFZJgn4MsNflfbI1zY1SaqRSajumpj/amhYOPAY8\nffZF9c3Ze0eivhBCeFNmDbla60la64aYID/BmvwU8KrWOsPXukqpEUqpJKVUUmpqaik/v2BbpVpf\nCCFKIzw8vLyLcEZKcnNWClDX5X2sNc2b6cDb1usOwPVKqZeBKCBfKZWptX7LdQWt9WRgMkBiYqKm\nFGRoZSGEKF5Jgv5yoLFSKh4T7IcBN7ouoJRqrLXear3tD2wF0Fp3cVnmKSCjcMAvK44zhaR3hLCR\n2ePgwLqy3WatBOj7ktfZ48aNo27duowcORKAp556ioCAABYuXMjRo0fJycnhueeeY+DAgV634ZCR\nkcHAgQM9rjd16lReeeUVlFK0atWKTz75hIMHD3LPPfewY8cOAN5++206d+5cBjvtVGzQ11rnKqVG\nAXMBf2CK1nqDUuoZIElrPQsYpZTqBeQAR4HhZVrKEpDHJQohysLQoUN54IEHCoL+F198wdy5cxk9\nejQREREcPnyYjh07MmDAgGLTySEhIXz99ddF1tu4cSPPPfccv//+O9WqVSsYvG306NFceeWVfP31\n1+Tl5ZGR4TMzXiolGntHa/0j8GOhaU+6vB5Tgm08daaFOxPyEBUhbMhHjfxcufTSSzl06BD79u0j\nNTWVKlWqUKtWLcaOHcvixYvx8/MjJSWFgwcPUqtWLZ/b0lrzxBNPFFlvwYIFDBkyhGrVqgHOsfkX\nLFjA1KlTAfD39ycyMrLM9882A645a/oS9YUQZ2fIkCHMmDGDAwcOMHToUKZNm0ZqaiorVqwgMDCQ\nuLg4MjMzi91Oadc7l+w3DEP5FkMIYQNDhw5l+vTpzJgxgyFDhpCenk6NGjUIDAxk4cKF7N69u0Tb\n8bZejx49+PLLL0lLSwOcY/P37NmTt982/WDy8vJIT08v832zXdCXhlwhxNlq0aIFJ06cICYmhtq1\na3PTTTeRlJREQkICU6dOpWnTpiXajrf1WrRowfjx47nyyitp3bo1Dz74IACvv/46CxcuJCEhgXbt\n2rFx48Yy3zcbpnfKuSBCCFtwPOgcoFq1aixdutTjcr4aW32tN3z4cIYPd+/zUrNmTb799ttSlLbk\nbFPTjwwNpH9CbWpGhJR3UYQQ4oJlm5p+XLVKTLqpbXkXQwhRAa1bt45bbrnFbVpwcDB//vlnOZXI\nO9sEfSGEKC8JCQmsXr26vItRIrZJ7wgh7MMxrIoo6my/Gwn6QogLSkhICGlpaRL4PdBak5aWRkhI\n6dsuJb0jhLigxMbGkpycTGlH3LW7kJAQYmNjS72+BH0hxAUlMDCQ+Pj48i6GbUl6RwghKhAJ+kII\nUYFI0BdCiApEXWgt5EqpVKBkoxl5Vg04XEbFuRhUtP0F2eeKQvb5zNTXWlcvbqELLuifLaVUktY6\nsbzLcb5UtP0F2eeKQvb53JD0jhBCVCAS9IUQogKxY9CfXN4FOM8q2v6C7HNFIft8Dtgupy+EEMI7\nO9b0hRBCeGGboK+U6qOU2qyU2qaUGlfe5SkrSqm6SqmFSqmNSqkNSqkx1vRopdTPSqmt1u8q1nSl\nlHrD+h7WKqUuyocMKKX8lVKrlFLfW+/jlVJ/Wvv1uVIqyJoebL3fZs2PK89ynw2lVJRSaoZSapNS\n6i+lVKcKcJzHWn/X65VS/6eUCrHbsVZKTVFKHVJKrXeZdsbHVSk13Fp+q1JquKfPKglbBH2llD8w\nCegLNAduUEo1L99SlZlc4CGtdXOgIzDS2rdxwHytdWNgvvUezHfQ2PoZAbx9/otcJsYAf7m8/zfw\nqta6EXAUuMOafgdw1Jr+qrXcxep1YI7WuinQGrP/tj3OSqkYYDSQqLVuCfgDw7Dfsf4I6FNo2hkd\nV6VUNPAvoAPQHviX40RxxrTWF/0P0AmY6/L+ceDx8i7XOdrXb4HewGagtjWtNrDZev0ucIPL8gXL\nXSw/QKz1j9AD+B5QmBtWAgofb2Au0Ml6HWAtp8p7H0qxz5HAzsJlt/lxjgH2AtHWsfseuNqOxxqI\nA9aX9rgCNwDvukx3W+5MfmxR08f5x+OQbE2zFety9lLgT6Cm1nq/NesAUNN6bYfv4jXgUSDfel8V\nOKa1zrXeu+5Twf5a89Ot5S828UAq8KGV1npfKVUJGx9nrXUK8AqwB9iPOXYrsP+xhjM/rmV2vO0S\n9G1PKRUOfAU8oLU+7jpPm1O/LbphKaWuAQ5prVeUd1nOswCgLfC21vpS4CTOS37AXscZwEpPDMSc\n8OoAlSiaBrG9831c7RL0U4C6Lu9jrWm2oJQKxAT8aVrrmdbkg0qp2tb82sAha/rF/l1cDgxQSu0C\npmNSPK8DUUopx/MfXPepYH+t+ZFA2vkscBlJBpK11o4nac/AnATsepwBegE7tdapWuscYCbm+Nv9\nWMOZH9cyO952CfrLgcZWq38QpjFoVjmXqUwopRTwAfCX1nqiy6xZgKMFfzgm1++Y/g+rF0BHIN3l\nMvKCp7V+XGsdq7WOwxzHBVrrm4CFwPXWYoX31/E9XG8tf9HVhrXWB4C9SqlLrEk9gY3Y9Dhb9gAd\nlVJh1t+5Y59tfawtZ3pc5wJXKaWqWFdIV1nTzlx5N3CUYUNJP2ALsB0YX97lKcP9ugJz6bcWWG39\n9MPkMucDW4F5QLS1vML0ZNoOrMP0jCj3/SjlvncDvrdeNwCWAduAL4Fga3qI9X6bNb9BeZf7LPa3\nDZBkHetvgCp2P87A08AmYD3wCRBst2MN/B+mzSIHc0V3R2mOK3C7te/bgNtKWx65I1cIISoQu6R3\nhBBClIAEfSGEqEAk6AshRAUiQV8IISoQCfpCCFGBSNAXQogKRIK+EEJUIBL0hRCiAvl/HAe1mHMU\nGn8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b4b3c2438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history.history['acc'], label='acc');\n",
    "plot(history.history['val_acc'], label='val_acc');\n",
    "legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
