{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import sys\n",
    "sys.path.append('/home/peter/code/projects')\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "from collections import Counter\n",
    "import time\n",
    "import progressbar as pb\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "import aidevutil.denoise as denoise\n",
    "from empyrical import sortino_ratio, calmar_ratio, omega_ratio\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy, ActorCriticPolicy, FeedForwardPolicy\n",
    "from stable_baselines.common.vec_env import SubprocVecEnv, VecEnv, VecEnvWrapper\n",
    "from stable_baselines import A2C, PPO2, DQN, ACKTR, ACER\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "import tensorflow as tf\n",
    "from trading_env import TradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize, gbrt_minimize, Optimizer\n",
    "from skopt.benchmarks import branin as branin\n",
    "from skopt.benchmarks import hart6 as hart6_\n",
    "from functools import partial\n",
    "from skopt.plots import plot_evaluations, plot_convergence\n",
    "from skopt.plots import plot_objective\n",
    "from skopt import gp_minimize, gbrt_minimize, forest_minimize, dummy_minimize\n",
    "from skopt import callbacks\n",
    "#from skopt.callbacks import CheckpointSaver\n",
    "from skopt import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the market data\n",
    "input_source = np.load(open('data_eurusd2.npy','rb'))\n",
    "to_predict = np.load(open('data_eurusd2_targets.npy','rb'))\n",
    "\n",
    "to_predict = to_predict[3,:].reshape(-1)\n",
    "\n",
    "input_source = input_source.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_source.shape, to_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_orig = np.copy(input_source)\n",
    "cp = int(0.8*len(input_source))\n",
    "test_input_source = input_source[cp:, :]\n",
    "test_to_predict = to_predict[cp:]\n",
    "input_source = input_source[0:cp, :]\n",
    "to_predict = to_predict[0:cp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_source.shape, to_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_per_episode = 1000\n",
    "winlen = 1\n",
    "traded_amt = 100000\n",
    "initial_balance = 10000000\n",
    "commission = 0\n",
    "slippage = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rl(args):\n",
    "    \n",
    "    afun, l1, l2, gamma, n_steps, ent_coef, vf_coef, vf_fisher_coef, learning_rate, max_grad_norm, kfac_clip, lr_schedule = args\n",
    "    afun = [tf.nn.relu, tf.nn.tanh, tf.nn.sigmoid][afun]\n",
    "    lr_schedule = ['linear', 'constant', 'double_linear_con', 'middle_drop', 'double_middle_drop'][lr_schedule]\n",
    "    \n",
    "    n_cpu = 32\n",
    "    env = SubprocVecEnv([lambda: TradingEnv(input_source, to_predict,\n",
    "                     winlen=winlen, bars_per_episode=bars_per_episode, traded_amt=traded_amt, initial_balance=initial_balance,\n",
    "                     commission=commission, slippage=slippage,\n",
    "                     reward_type='cur_balance',\n",
    "                     min_ratio_trades = 20,\n",
    "                     max_position_time = 30,\n",
    "                     ) for i in range(n_cpu)])\n",
    "    \n",
    "    policy_kwargs = dict(act_fun=afun, net_arch=[int(l1), int(l2)])\n",
    "    \n",
    "    model = ACKTR(MlpPolicy, env, verbose=0, \n",
    "                  gamma=gamma,\n",
    "                  nprocs=8,\n",
    "                  n_steps=n_steps,\n",
    "                  ent_coef=ent_coef,\n",
    "                  vf_coef=vf_coef,\n",
    "                  vf_fisher_coef=vf_fisher_coef,\n",
    "                  learning_rate=learning_rate,\n",
    "                  max_grad_norm=max_grad_norm,\n",
    "                  kfac_clip=kfac_clip,\n",
    "                  lr_schedule=lr_schedule,\n",
    "                  policy_kwargs=policy_kwargs, \n",
    "                  tensorboard_log='/home/peter/tblog')\n",
    "\n",
    "    model.learn(total_timesteps=3_000_000)\n",
    "    \n",
    "    # now test the model, return the negative profit ratio (because we are MINIMIZING)\n",
    "    env = TradingEnv(test_input_source, test_to_predict,\n",
    "                 winlen=winlen, bars_per_episode=bars_per_episode, traded_amt=traded_amt,\n",
    "                 commission=commission, slippage=slippage,\n",
    "                 reward_type='cur_balance',\n",
    "                 min_ratio_trades = 20,\n",
    "                 max_position_time = 30,\n",
    "                 )\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "    # calculate the likelihood of success for any given episode\n",
    "    l = 100\n",
    "    krl = []\n",
    "    p = pb.ProgressBar(max_value=l)\n",
    "    for i in range(l):\n",
    "        p.update(i)\n",
    "        observation = env.envs[0].reset()\n",
    "        nstate = model.initial_state\n",
    "        done = False\n",
    "        navs = []\n",
    "        for i in (range(env.envs[0].bars_per_episode)):\n",
    "            action, nstate = model.predict([observation], state=nstate, deterministic=1)\n",
    "            observation, reward, done, info = env.envs[0].step(action)\n",
    "            if done:\n",
    "                break\n",
    "        krl.append(sum(env.envs[0].returns ))\n",
    "    p.finish()\n",
    "\n",
    "    krl = np.array(krl)\n",
    "    pli = (100*(sum(krl > 0) / len(krl)))\n",
    "    print('Profit likelihood: %3.3f%%' % pli)\n",
    "    return 100-pli\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer([(0, 2), # afun\n",
    "                 (32, 256), # l1\n",
    "                 (32, 256), # l2\n",
    "                 (0.75, 0.9999), # gamma\n",
    "                 (5, 100), # n_steps\n",
    "                 (0.0, 0.25), # ent_coef\n",
    "                 (0.1, 0.6), # vf_coef\n",
    "                 (0.2, 1.0), # vf_fisher_coef\n",
    "                 (0.02, 0.75), # learning_rate\n",
    "                 (0.1, 0.8), # max_grad_norm\n",
    "                 (0.0, 0.05), # kfac_clip\n",
    "                 (0, 4)]) # lr_schedule\n",
    "\n",
    "best_y_ever = 99999999\n",
    "for i in tqdm(range(1000)):\n",
    "    suggested = opt.ask()\n",
    "    print('Trying:', suggested)\n",
    "    y = test_rl(suggested)\n",
    "    opt.tell(suggested, y)\n",
    "    print('iteration:', i, suggested, y)\n",
    "    if y < best_y_ever:\n",
    "        best_y_ever = y\n",
    "        pkl.dump(suggested, open('best_params.pkl','wb'))\n",
    "        print('Saved best parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
