{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "from collections import Counter\n",
    "import time\n",
    "import progressbar as pb\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from empyrical import sortino_ratio, calmar_ratio, omega_ratio\n",
    "from stable_baselines.common.policies import MlpPolicy, MlpLstmPolicy\n",
    "from stable_baselines.common.vec_env import SubprocVecEnv, VecEnv, VecEnvWrapper\n",
    "from stable_baselines import A2C, PPO2\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "\n",
    "import progressbar as pb\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, LSTM, Reshape, Dropout, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.cem import CEMAgent \n",
    "from rl.agents.ddpg import DDPGAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory, EpisodeParameterMemory\n",
    "from rl.processors import WhiteningNormalizerProcessor\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "from trading_env import TradingEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the market data\n",
    "input_source = np.load(open('data_dummy.npy','rb'))\n",
    "to_predict = np.load(open('data_dummy_targets.npy','rb'))\n",
    "\n",
    "to_predict = to_predict[3,:].reshape(-1)\n",
    "\n",
    "input_source = input_source.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_orig = np.copy(input_source)\n",
    "cp = int(0.8*len(input_source))\n",
    "test_input_source = input_source[cp:, :]\n",
    "test_to_predict = to_predict[cp:]\n",
    "input_source = input_source[0:cp, :]\n",
    "to_predict = to_predict[0:cp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_per_episode = 1000\n",
    "winlen = 1\n",
    "traded_amt = 1000\n",
    "commission = 0\n",
    "slippage = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiprocess environment\n",
    "#n_cpu = 16\n",
    "#env = SubprocVecEnv([lambda: TradingEnv() for i in range(n_cpu)])\n",
    "env = TradingEnv(input_source, to_predict,\n",
    "                 winlen=winlen, bars_per_episode=bars_per_episode, traded_amt=traded_amt,\n",
    "                 commission=commission, slippage=slippage,\n",
    "                 reward_type='cur_balance',\n",
    "                 min_ratio_trades = 20,\n",
    "                 max_position_time = 30,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MultiNEAT as NEAT\n",
    "import MultiNEAT.viz as viz\n",
    "import random as rnd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "rng = NEAT.RNG()\n",
    "rng.TimeSeed()\n",
    "\n",
    "params = NEAT.Parameters()\n",
    "params.PopulationSize = 150\n",
    "params.DynamicCompatibility = True\n",
    "params.WeightDiffCoeff = 1.0\n",
    "params.CompatTreshold = 2.0\n",
    "params.YoungAgeTreshold = 15\n",
    "params.SpeciesMaxStagnation = 15\n",
    "params.OldAgeTreshold = 35\n",
    "params.MinSpecies = 2\n",
    "params.MaxSpecies = 4\n",
    "params.RouletteWheelSelection = False\n",
    "params.Elitism = True\n",
    "params.RecurrentProb = 0.15\n",
    "params.OverallMutationRate = 0.2\n",
    "\n",
    "params.MutateWeightsProb = 0.8\n",
    "params.MutateNeuronTimeConstantsProb = 0.1\n",
    "params.MutateNeuronBiasesProb = 0.1\n",
    "\n",
    "params.WeightMutationMaxPower = 0.5\n",
    "params.WeightReplacementMaxPower = 1.0\n",
    "params.MutateWeightsSevereProb = 0.5\n",
    "params.WeightMutationRate = 0.25\n",
    "\n",
    "params.TimeConstantMutationMaxPower = 0.1\n",
    "params.BiasMutationMaxPower = params.WeightMutationMaxPower\n",
    "\n",
    "params.MaxWeight = 8\n",
    "\n",
    "params.MutateAddNeuronProb = 0.1\n",
    "params.MutateAddLinkProb = 0.2\n",
    "params.MutateRemLinkProb = 0.0\n",
    "\n",
    "params.MinActivationA  = 1.0\n",
    "params.MaxActivationA  = 6.0\n",
    "\n",
    "params.MinNeuronTimeConstant = 0.04\n",
    "params.MaxNeuronTimeConstant = 0.24\n",
    "\n",
    "params.MinNeuronBias = -params.MaxWeight\n",
    "params.MaxNeuronBias = params.MaxWeight\n",
    "\n",
    "params.ActivationFunction_SignedSigmoid_Prob = 0.0\n",
    "params.ActivationFunction_UnsignedSigmoid_Prob = 0.0\n",
    "params.ActivationFunction_Tanh_Prob = 1.0\n",
    "params.ActivationFunction_SignedStep_Prob = 0.0\n",
    "params.ActivationFunction_Linear_Prob = 0.0\n",
    "\n",
    "params.CrossoverRate = 0.75  # mutate only 0.25\n",
    "params.MultipointCrossoverRate = 0.4\n",
    "params.SurvivalRate = 0.2\n",
    "\n",
    "params.MutateNeuronTraitsProb = 0\n",
    "params.MutateLinkTraitsProb = 0\n",
    "\n",
    "\n",
    "trials = 15\n",
    "render_during_training = 0\n",
    "\n",
    "g = NEAT.Genome(0, int(np.prod(env.observation_space.shape))+1, 0, env.action_space.n, False,\n",
    "                    NEAT.ActivationFunction.TANH, NEAT.ActivationFunction.TANH, 0, params, 0)\n",
    "pop = NEAT.Population(g, params, True, 1.0, rnd.randint(0, 1000))\n",
    "\n",
    "\n",
    "hof = []\n",
    "maxf_ever = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_with_nn(observation):\n",
    "    inp = observation.tolist()\n",
    "    net.Input(inp + [1.0])\n",
    "    #print(inp)\n",
    "    net.ActivateLeaky(0.1)\n",
    "    out = list(net.Output())\n",
    "    return out\n",
    "\n",
    "\n",
    "def do_trial():\n",
    "    #observation, reward, t, img, action, done, info, avg_reward\n",
    "    observation = env.reset()\n",
    "    net.Flush()\n",
    "\n",
    "    f = 0\n",
    "    for t in range(bars_per_episode):\n",
    "        out = interact_with_nn(observation)\n",
    "        action = np.argmax(out)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done: break\n",
    "        f += reward\n",
    "    return f/t\n",
    "\n",
    "try:\n",
    "\n",
    "    for generation in range(200):\n",
    "        for i_episode, genome in tqdm(enumerate(NEAT.GetGenomeList(pop))):\n",
    "            net = NEAT.NeuralNetwork()\n",
    "            genome.BuildPhenotype(net)\n",
    "            avg_reward = 0\n",
    "            for trial in range(trials):\n",
    "                avg_reward += do_trial()\n",
    "            avg_reward /= trials\n",
    "            genome.SetFitness(avg_reward)\n",
    "\n",
    "        maxf = max([x.GetFitness() for x in NEAT.GetGenomeList(pop)])\n",
    "        print('Generation: {}, max fitness: {}'.format(generation, maxf))\n",
    "\n",
    "        if maxf > maxf_ever:\n",
    "            hof.append(pickle.dumps(pop.GetBestGenome()))\n",
    "            maxf_ever = maxf\n",
    "\n",
    "        pop.Epoch()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TradingEnv(test_input_source, test_to_predict,\n",
    "                 winlen=winlen, bars_per_episode=bars_per_episode, traded_amt=traded_amt,\n",
    "                 commission=commission, slippage=slippage,\n",
    "                 reward_type='cur_balance',\n",
    "                 min_ratio_trades = 20,\n",
    "                 max_position_time = 30,\n",
    "                 )\n",
    "# visualize the behavior for one random episode\n",
    "bars_per_episode = 1000\n",
    "\n",
    "observation = env.reset()\n",
    "done = False\n",
    "navs = []\n",
    "while not done:\n",
    "    action = agent.forward(observation)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    navs.append(reward)\n",
    "\n",
    "kl = []\n",
    "t = 0\n",
    "for n in navs:\n",
    "    t += n\n",
    "    kl.append(t)\n",
    "plot(kl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the likelihood of success for any given episode\n",
    "try:\n",
    "    # calculate the likelihood of success for any given episode\n",
    "    l = 100\n",
    "    krl = []\n",
    "    p = pb.ProgressBar(max_value=l)\n",
    "    for i in range(l):\n",
    "        p.update(i)\n",
    "        observation = env.reset()\n",
    "        done = False\n",
    "        navs = []\n",
    "        while not done:\n",
    "            action = agent.forward(observation)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            navs.append(reward)\n",
    "        krl.append(sum(navs))\n",
    "    p.finish()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "krl = np.array(krl)\n",
    "print('Profit likelihood: %3.3f%%' % (100*(sum(krl > 0) / len(krl))))\n",
    "\n",
    "hist(krl);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
